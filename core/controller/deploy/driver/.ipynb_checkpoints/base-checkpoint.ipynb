{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file arthur_microservice.py\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "# author: leepand\n",
    "# time: 2019-01-28\n",
    "# desc: 服务部署基础组件\n",
    "import os\n",
    "from Arthur.core.utils.store.exp_file_process import FileStore\n",
    "from Arthur.core.utils.store.file_utils import list_subdirs\n",
    "from Arthur.core.utils import  port_for\n",
    "from Arthur.core.utils.token_util import Connector\n",
    "from Arthur.core.entities.bean.Arthur_service import ArthurService\n",
    "from Arthur.core.entities.base.bs_time import get_cur_day\n",
    "from Arthur.core.entities.bean.hjs_user import HjsUser\n",
    "\n",
    "\n",
    "class ArthurMicroserviceDeployDriver(object):\n",
    "    \"\"\"\n",
    "    Arthur Microservice deployment driver\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, end_point, api_key):\n",
    "        self.end_point = end_point\n",
    "        self.api_key = api_key\n",
    "        self.commands = Commands()\n",
    "        self.status = Status\n",
    "\n",
    "    def validate_deploy(self, home, environment_directory_path):\n",
    "        \"\"\"\n",
    "        Validate deployment before packaging the project to push\n",
    "        \"\"\"\n",
    "        response = Response()\n",
    "        bool_environment, bool_config_exists, bool_methods_exists, message = False, False, False, \"\"\n",
    "        # 1. Check for environment file\n",
    "        if os.path.exists(os.path.join(environment_directory_path, \"Dockerfile\")) or \\\n",
    "                os.path.exists(os.path.join(home,  \"Dockerfile\")):\n",
    "            bool_environment = True\n",
    "        else:\n",
    "            message = \"No Dockerfile exists in the project.\"\n",
    "        # 2. Check for existance of datmo deploy config file\n",
    "        if os.path.exists(os.path.join(home, 'datmo-deploy.yml')):\n",
    "            datmo_deploy_config_path = os.path.join(home, 'datmo-deploy.yml')\n",
    "            bool_config_exists = True\n",
    "        elif os.path.exists(os.path.join(home, 'datmo-deploy.yaml')):\n",
    "            datmo_deploy_config_path = os.path.join(home, 'datmo-deploy.yaml')\n",
    "            bool_config_exists = True\n",
    "        else:\n",
    "            message += \" No config file exist in the project.\"\n",
    "            datmo_deploy_config_path = None\n",
    "\n",
    "        if datmo_deploy_config_path:\n",
    "            with open(datmo_deploy_config_path, 'r') as stream:\n",
    "                try:\n",
    "                    datmo_deploy = yaml.safe_load(stream)\n",
    "                    if datmo_deploy is not None:\n",
    "                        worker_path = datmo_deploy['deploy'][\n",
    "                            'celery_services']['worker_path']\n",
    "                        config_method_names = datmo_deploy['deploy'][\n",
    "                            'celery_services']['methods']\n",
    "                        # 3. Check for methods declared in config and what exists in worker file\n",
    "                        if os.path.exists(os.path.join(home, worker_path)):\n",
    "                            filepath = os.path.join(home, worker_path)\n",
    "                            with open(filepath, \"rt\") as file:\n",
    "                                parse_ast = ast.parse(\n",
    "                                    file.read(), filename=worker_path)\n",
    "                            body = parse_ast.body\n",
    "                            method_names = []\n",
    "                            for f in body:\n",
    "                                if isinstance(f, ast.FunctionDef):\n",
    "                                    method_names.append(f.name)\n",
    "                            if len(\n",
    "                                    set(config_method_names) & set(\n",
    "                                        method_names)) == len(\n",
    "                                            config_method_names):\n",
    "                                bool_methods_exists = True\n",
    "                            else:\n",
    "                                message += \" Methods mentioned in the config file does not exist in worker file.\"\n",
    "                except yaml.YAMLError as exc:\n",
    "                    print(exc)\n",
    "\n",
    "        response.message = bcolors.FAIL + message + bcolors.ENDC\n",
    "        bool_validate = (bool_environment and bool_config_exists\n",
    "                         and bool_methods_exists)\n",
    "        if not bool_validate:\n",
    "            response.status = self.status.FAILURE\n",
    "\n",
    "        return bool_validate, response\n",
    "\n",
    "    def check_setup(self, response):\n",
    "        # in case of no proper setup\n",
    "        if self.end_point is not None:\n",
    "            return True, response\n",
    "        response.message = bcolors.FAIL + \"Setup for remote datmo isn't done. \" \\\n",
    "                                          \"Run `datmo configure` and configure your remote credentials \" + bcolors.ENDC\n",
    "        response.status = self.status.FAILURE\n",
    "        return False, response\n",
    "\n",
    "    def create_cluster(self, cluster_name=None, server_type=None, count=None):\n",
    "        response = Response()\n",
    "        bool_setup, response = self.check_setup(response)\n",
    "        if not bool_setup:\n",
    "            return response\n",
    "        if cluster_name:\n",
    "            self.cluster_name = cluster_name\n",
    "        if server_type:\n",
    "            self.server_type = server_type\n",
    "        if count:\n",
    "            self.count = str(count)\n",
    "\n",
    "        shell_cmd = 'curl -d \\'{\"cluster_name\": \"%s\", \"server_type\": \"%s\", \"count\": %s}\\' -H \"Content-Type: application/json\" -H \"authorization:%s\" -X POST %s/cluster' % (\n",
    "            self.cluster_name, self.server_type, self.count, self.api_key,\n",
    "            self.end_point)\n",
    "        command_run = self.commands.run_cmd(shell_cmd)\n",
    "        if not command_run['status']:\n",
    "            response.message = bcolors.FAIL + \"error while creating the cluster\" + bcolors.ENDC\n",
    "            response.status = self.status.FAILURE\n",
    "        return response\n",
    "\n",
    "    def update_cluster(self, count, cluster_name=None):\n",
    "        response = Response()\n",
    "        bool_setup, response = self.check_setup(response)\n",
    "        if not bool_setup:\n",
    "            return response\n",
    "        self.count = count\n",
    "        if cluster_name:\n",
    "            self.cluster_name = cluster_name\n",
    "        shell_cmd = 'curl -d \\'{\"count\": %s}\\' -H \"Content-Type: application/json\"  -H \"authorization:%s\" -X PUT %s/cluster/%s'\\\n",
    "                    % (self.count, self.api_key, self.end_point, self.cluster_name)\n",
    "        command_run = self.commands.run_cmd(shell_cmd)\n",
    "        if not command_run['status']:\n",
    "            response.message = bcolors.FAIL + \"error while updating the cluster\" + bcolors.ENDC\n",
    "            response.status = self.status.FAILURE\n",
    "        return response\n",
    "\n",
    "    def get_cluster_info(self, cluster_name):\n",
    "        response = Response()\n",
    "        bool_setup, response = self.check_setup(response)\n",
    "        if not bool_setup:\n",
    "            return response\n",
    "        self.cluster_name = cluster_name\n",
    "        url = '%s/cluster/%s' % (self.end_point, self.cluster_name)\n",
    "        res = authenticated_get_call(url, access_key=self.api_key)\n",
    "        if res.status_code != 200:\n",
    "            response.message = bcolors.FAIL + \"error while getting the information about the cluster\" + bcolors.ENDC\n",
    "            response.status = self.status.FAILURE\n",
    "            return response\n",
    "        response.result = res.json()\n",
    "        return response\n",
    "\n",
    "    def get_system_info(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        To return the Kibana and Grafana links and credentials for it\n",
    "        \"\"\"\n",
    "        response = Response()\n",
    "        bool_setup, response = self.check_setup(response)\n",
    "        if not bool_setup:\n",
    "            return response\n",
    "        url = '%s/info' % self.end_point\n",
    "        res = authenticated_get_call(url, access_key=self.api_key)\n",
    "        if res.status_code != 200:\n",
    "            response.message = bcolors.FAIL + \"error while getting the information about the cluster\" + bcolors.ENDC\n",
    "            response.status = self.status.FAILURE\n",
    "            return response\n",
    "        response.result = res.json()\n",
    "        return response\n",
    "\n",
    "    def get_system_cost(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        cost of the current system from the cloud service\n",
    "        \"\"\"\n",
    "        response = Response()\n",
    "        bool_setup, response = self.check_setup(response)\n",
    "        if not bool_setup:\n",
    "            return response\n",
    "        url = '%s/cost_estimate' % self.end_point\n",
    "        res = authenticated_get_call(url, access_key=self.api_key)\n",
    "        if res.status_code != 200:\n",
    "            response.message = bcolors.FAIL + \"error while getting the information about the cluster\" + bcolors.ENDC\n",
    "            response.status = self.status.FAILURE\n",
    "            return response\n",
    "        response.result = res.json()\n",
    "        return response\n",
    "\n",
    "    def model_deploy(self, cluster_name, file=None):\n",
    "        response = Response()\n",
    "        bool_setup, response = self.check_setup(response)\n",
    "        if not bool_setup:\n",
    "            return response\n",
    "        self.cluster_name = cluster_name\n",
    "        shell_cmd = 'curl  -H \"authorization:%s\" -F \\'service=@%s\\' %s/cluster/%s/deploy' % (\n",
    "            self.api_key, file, self.end_point, self.cluster_name)\n",
    "        command_run = self.commands.run_cmd(shell_cmd)\n",
    "        if not command_run['status']:\n",
    "            response.message = bcolors.FAIL + \"error while deploying the model onto the cluster\" + bcolors.ENDC\n",
    "            response.status = self.status.FAILURE\n",
    "        return response\n",
    "\n",
    "    def get_service_iologs(self, service_path, date):\n",
    "        response = Response()\n",
    "        bool_setup, response = self.check_setup(response)\n",
    "        if not bool_setup:\n",
    "            return response\n",
    "        # get the proper service path\n",
    "        service_path = service_path.strip()\n",
    "        if service_path[0] == '/':\n",
    "            service_path = service_path[1:]\n",
    "        url = '%s/iologs/%s?date=%s' % (self.end_point, service_path, date)\n",
    "        res = authenticated_get_call(url, access_key=self.api_key)\n",
    "        if res.status_code not in [200, 201]:\n",
    "            response.message = bcolors.FAIL + 'DOWNLOAD io logs failed: ' + res.text + bcolors.ENDC\n",
    "            response.status = self.status.FAILURE\n",
    "        path = service_path.replace('/', '.') + '-' + date.replace(\n",
    "            '/', '.') + '.tar.gz'\n",
    "        with open(path, 'wb') as f:\n",
    "            for chunk in res:\n",
    "                f.write(chunk)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "from Arthur.core.utils.store.exp_file_process import FileStore\n",
    "from Arthur.core.utils.store.file_utils import list_subdirs\n",
    "from Arthur.core.utils import  port_for\n",
    "from Arthur.core.utils.token_util import Connector\n",
    "from Arthur.core.entities.bean.Arthur_service import ArthurService\n",
    "from Arthur.core.entities.base.bs_time import get_cur_day\n",
    "from Arthur.core.entities.base.bs_log import Log\n",
    "from Arthur.core.entities.bean.hjs_user import HjsUser\n",
    "from Arthur.core.utils.algo_publish import model_publish\n",
    "from Arthur.core.utils.spinner import Spinner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_class=model_publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "# author: leepand\n",
    "# time: 2019-01-28\n",
    "# desc: 服务部署基础组件\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "from Arthur.core.utils.store.exp_file_process import FileStore\n",
    "from Arthur.core.utils.store.file_utils import list_subdirs\n",
    "from Arthur.core.utils import  port_for\n",
    "from Arthur.core.utils.token_util import Connector\n",
    "from Arthur.core.entities.bean.Arthur_service import ArthurService\n",
    "from Arthur.core.entities.base.bs_time import get_cur_day\n",
    "from Arthur.core.entities.base.bs_log import Log\n",
    "from Arthur.core.entities.bean.hjs_user import HjsUser\n",
    "from Arthur.core.utils.algo_publish import model_publish\n",
    "from Arthur.core.utils.spinner import Spinner\n",
    "\n",
    "\n",
    "class ArthurMicroserviceDeployDriver(object):\n",
    "    \"\"\"\n",
    "    Arthur Microservice deployment driver\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,cmd_pub_type):\n",
    "        self.pub_type= cmd_pub_type#local/remote\n",
    "        self.spinner = Spinner()\n",
    "    def wait_until_algo_published(\n",
    "        self,publish_status,aId, max_wait_sec=20, interval_sec=0.1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        wait util the algo published or timeout\n",
    "        :param publish_status:\n",
    "            publish status for wait :RUNNING,FAILED,FINISHED\n",
    "        :param max_wait_sec:\n",
    "            max wating time until timeout\n",
    "        :param interval_sec:\n",
    "            check interval\n",
    "        :return:\n",
    "            True if algorithm service publish success.\n",
    "        \"\"\"\n",
    "        curr_wait_sec = 0\n",
    "        spinner_generator = itertools.cycle(['-', '/', '|', '\\\\'])\n",
    "        while curr_wait_sec < max_wait_sec:\n",
    "        \n",
    "            if publish_status==\"FAILED\" or publish_status==\"FINISHED\" :\n",
    "                if aId is not None:\n",
    "                    ArthurService.algo_publish_status_update(aId,'stop')\n",
    "                return False\n",
    "            curr_wait_sec += interval_sec\n",
    "            sys.stdout.write(next(spinner_generator))\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(interval_sec)\n",
    "            sys.stdout.write('\\b')  \n",
    "        #对发布的算法状态进行更新\n",
    "        if aId is not None:\n",
    "            ArthurService.algo_publish_status_update(aId,'normal')\n",
    "        ret=\"algorithm service publish success!\"\n",
    "        Log.info(\"****RESP: %s\" % ret)\n",
    "        return True\n",
    "    def createExpInfo(self,userName):\n",
    "        project_path=os.path.abspath('arthur_runs/'+userName)\n",
    "        create_exp=FileStore(root_directory=project_path)\n",
    "        return create_exp\n",
    "    def getExpInfo(self,userName,projectName):  \n",
    "        project_path=os.path.abspath('arthur_runs/'+userName)      \n",
    "        #rel_path='arthur_runs/'+self.get_user_name()\n",
    "        process_exp=FileStore(root_directory=project_path) \n",
    "        if process_exp.get_experiment_by_name(projectName) is None:\n",
    "            return False,'No project to publish'\n",
    "        return process_exp\n",
    "        \n",
    "    def algoInfoAdd(self,userName,projectName,funcsPath,funcList,algoField=1,port=None,\\\n",
    "                   projecttm=None,remark=None,emailmsg=None,opertype=None,projectdesc=None,tags=None):\n",
    "        \"\"\"\n",
    "        Validate deployment before packaging the project to push\n",
    "        prepare algo info for deploy, \n",
    "        copy user's algo project to arthur runs path/user\n",
    "        \"\"\"\n",
    "        _bRet,uId=HjsUser.get_user_uid(userName)\n",
    "        if not _bRet:\n",
    "            return False, uId  \n",
    "        create_exp = self.createExpInfo(userName)\n",
    "        rel_path='arthur_runs/'+userName\n",
    "        #迁移源项目路径至新建路径\n",
    "        create_exp.create_experiment(funcsPath,projectName)\n",
    "        Token_gen=Connector.encrypt_token( 1, str(uId), 'session_token')\n",
    "        Token_info=Token_gen['token']\n",
    "        funcspath_bath = os.path.join(create_exp.get_experiment_by_name(projectName).artifact_location,projectName)\n",
    "        funcs_sub=list_subdirs(funcspath_bath)\n",
    "        run_path=os.path.join(funcspath_bath,funcs_sub[0])#一个项目只有一个主目录-default\n",
    "        if port is None:\n",
    "            port=port_for.select_random()\n",
    "        if projecttm is None:\n",
    "            projecttm = get_cur_day(0, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        if remark is None:\n",
    "            remark=\"请到主页编辑添加\"\n",
    "        if emailmsg is None:\n",
    "            emailmsg=\"是\"\n",
    "        if opertype is None:\n",
    "            opertype=\"publish\"\n",
    "        if projectdesc is None:\n",
    "            projectdesc=\"暂无描述，请到主页编辑添加\"\n",
    "        if tags is None:\n",
    "            tags='Machine Learning'\n",
    "        ArthurService.service_add(uId,projectName, projectdesc,opertype,rel_path,\n",
    "                                     funcList,tags,algoField,'0.0.0.0',port,projecttm,emailmsg,str(remark))\n",
    "        return create_exp,uId\n",
    "    def algoDeployCli(self,funcsPath,funcList,userName=None,projectName=None,port=None,token=''):\n",
    "        pub_type=self.pub_type\n",
    "        publish_class=model_publish()\n",
    "        if pub_type==\"local\":\n",
    "            if port is None:\n",
    "                port=port_for.select_random()\n",
    "            run_path = funcsPath\n",
    "            publish_status = publish_class._invoke_arthur_run_subprocess(funcList,experiment_id=1,run_id=1,token=token,port=port,runpath=run_path)\n",
    "            publish_status,pid_info = publish_status.get_status()\n",
    "            wait_result = self.wait_until_algo_published(publish_status,aId=None) \n",
    "            host =\"0.0.0.0\"\n",
    "            bind_address = \"%s:%s\" % (host, port)\n",
    "            if wait_result:\n",
    "                Log.info('algo deploy success')\n",
    "                Log.info('the end point of your algo service %s is %s'% (funcList,bind_address))\n",
    "                return True,'algo deploy success'\n",
    "            else:\n",
    "                Log.err(\"algo deploy failed\");\n",
    "                return False,'algo deploy failed'\n",
    "    \n",
    "        else:\n",
    "            self.spinner.start()\n",
    "            create_exp_info,uId = self.algoInfoAdd(userName,projectName,funcsPath,funcList,port=port)#port非指定的情况系统自动生成\n",
    "            self.spinner.stop()\n",
    "            _bRet,algoInfo = ArthurService.algo_proj_info(uId,projectName)#AlgoName=projectName\n",
    "            #funcslist=algoInfo['funcslist']\n",
    "            port=algoInfo['port']\n",
    "            token=algoInfo['token']\n",
    "            aId = algoInfo['aid']\n",
    "            experiment_id=create_exp_info.get_experiment_by_name(projectName).experiment_id\n",
    "            runId= aId\n",
    "            funcspath_bath = os.path.join(create_exp_info.get_experiment_by_name(projectName).artifact_location,projectName)        \n",
    "            funcs_sub=list_subdirs(funcspath_bath)\n",
    "            run_path=os.path.join(funcspath_bath,funcs_sub[0])            \n",
    "            publish_status = publish_class._invoke_arthur_run_subprocess(funcList,experiment_id,runId,token=token,port=port,runpath=run_path)\n",
    "            #将pid写入项目目录\n",
    "            pidPath=create_exp_info.get_experiment_by_name(projectName).artifact_location\n",
    "            publish_status,pid_info = publish_status.get_status()\n",
    "            generated_pid_filename = os.path.join(pidPath,\"pid.pid\")\n",
    "            with open(generated_pid_filename, \"w\") as f:\n",
    "                f.write(str(pid_info))\n",
    "            wait_result = self.wait_until_algo_published(publish_status,aId) \n",
    "            host =\"0.0.0.0\"\n",
    "            bind_address = \"%s:%s\" % (host, port)\n",
    "            if wait_result:\n",
    "                Log.info('algo deploy success')\n",
    "                Log.info('the end point of your algo service %s is %s'% (funcList,bind_address))\n",
    "                return True,'algo deploy success'\n",
    "            else:\n",
    "                Log.err(\"algo deploy failed\");\n",
    "                return False,'algo deploy failed'\n",
    "    def algoDeployUI(self,aId,userName):\n",
    "        publish_class=model_publish()\n",
    "        self.spinner.start()\n",
    "        _bRet , algo_info = ArthurService.algo_info(aId)\n",
    "        if not _bRet:\n",
    "            return False, algo_info\n",
    "        projectName=algo_info['algoname'] \n",
    "        #userName=algo_info['username']\n",
    "        funcslist=algo_info['funcslist']\n",
    "        port=algo_info['port']\n",
    "        token=algo_info['token']\n",
    "        uId=algo_info['uid']\n",
    "        process_exp = self.getExpInfo(userName,projectName) \n",
    "        #_bRet,uId=HjsUser.get_user_uid(userName)\n",
    "        #if not _bRet:\n",
    "        #    return False, uId  \n",
    "        #create_exp_info,uId = self.algoInfoAdd(userName,projectName,funcsPath,funcList)\n",
    "        self.spinner.stop()    \n",
    "        #_bRet,algoInfo = ArthurService.algo_proj_info(uId,projectName)#AlgoName=projectName\n",
    "        #funcslist=algoInfo['funcslist']\n",
    "        #funcslist=algoInfo['funcslist']\n",
    "        #port=algoInfo['port']\n",
    "        #token=algoInfo['token']\n",
    "        #aId = algoInfo['aid']\n",
    "        experiment_id=process_exp.get_experiment_by_name(projectName).experiment_id\n",
    "        runId= aId\n",
    "        funcspath_bath = os.path.join(process_exp.get_experiment_by_name(projectName).artifact_location,projectName)        \n",
    "        funcs_sub=list_subdirs(funcspath_bath)\n",
    "        run_path=os.path.join(funcspath_bath,funcs_sub[0])            \n",
    "        publish_status = publish_class._invoke_arthur_run_subprocess(funcslist,experiment_id,runId,token=token,port=port,runpath=run_path)\n",
    "        #将pid写入项目目录\n",
    "        pidPath=process_exp.get_experiment_by_name(projectName).artifact_location\n",
    "        publish_status,pid_info = publish_status.get_status()\n",
    "        generated_pid_filename = os.path.join(pidPath,\"pid.pid\")\n",
    "        with open(generated_pid_filename, \"w\") as f:\n",
    "            f.write(str(pid_info))\n",
    "        wait_result = self.wait_until_algo_published(publish_status,aId) \n",
    "        host =\"0.0.0.0\"\n",
    "        bind_address = \"%s:%s\" % (host, port)\n",
    "        if wait_result:\n",
    "            Log.info('algo deploy success')\n",
    "            Log.info('the end point of your algo service %s is %s'% (funcslist,bind_address))\n",
    "            return True,'algo deploy success'\n",
    "        else:\n",
    "            Log.err(\"algo deploy failed\");\n",
    "            return False,'algo deploy failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_info_publish = ArthurMicroserviceDeployDriver('remote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_info_publish.algoDeployUI(1,'leepand6')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
