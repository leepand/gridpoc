{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file bandits.py\n",
    "from random import random, choice, uniform, betavariate\n",
    "from math import log, exp, expm1\n",
    "\n",
    "class Bandit(object):\n",
    "    \"\"\"The primary bandit interface.  Don't use this unless you really\n",
    "    want uniform random arm selection (which defeats the whole purpose, really)\n",
    "    Used as a control to test against and as an interface to define methods against.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def fromdict(cls, dict_spec):\n",
    "        extra_args = dict([(key, value) for key, value in dict_spec.items() if key not in [\"arms\", \"pulls\", \"reward\", \"values\", \"bandit_type\", \"confidence\"]])\n",
    "\n",
    "        bandit = globals()[dict_spec[\"bandit_type\"]](**extra_args)\n",
    "        bandit.arms = dict_spec[\"arms\"]\n",
    "        bandit.pulls = dict_spec[\"pulls\"]\n",
    "        bandit.reward = dict_spec[\"reward\"]\n",
    "        bandit.values = dict_spec[\"values\"]\n",
    "        bandit.confidence = dict_spec.get(\"confidence\", [0.0] * len(bandit.arms))\n",
    "        return bandit\n",
    "\n",
    "    def __init__(self):\n",
    "        self.arms = []\n",
    "        self.pulls = []\n",
    "        self.reward = []\n",
    "        self.values = []\n",
    "        self.confidence = []\n",
    "\n",
    "    def add_arm(self, arm_id, value=None):\n",
    "        self.arms.append(arm_id)\n",
    "        self.pulls.append(0)\n",
    "        self.reward.append(0.0)\n",
    "        self.confidence.append(0.0)\n",
    "        self.values.append(value)\n",
    "\n",
    "    def pull_arm(self, arm_id):\n",
    "        ind = self.arms.index(arm_id)\n",
    "        if ind > -1:\n",
    "            self.pulls[ind] += 1\n",
    "\n",
    "    def reward_arm(self, arm_id, reward):\n",
    "        ind = self.arms.index(arm_id)\n",
    "        if ind > -1:\n",
    "            self.reward[ind] += reward\n",
    "        self._update(ind, reward)\n",
    "\n",
    "    def _update(self, arm_index, reward):\n",
    "        n = max(1, self.pulls[arm_index])\n",
    "        current = self.confidence[arm_index]\n",
    "        self.confidence[arm_index] = ((n - 1) / float(n)) * current + (1 / float(n)) * reward\n",
    "\n",
    "    def suggest_arm(self):\n",
    "        \"\"\"Uniform random for default bandit.\n",
    "        Just uses random.choice to choose between arms\n",
    "        \"\"\"\n",
    "        return self[random.choice(self.arms)]\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        ind = self.arms.index(key)\n",
    "        if ind > -1:\n",
    "            arm = {\n",
    "                    \"id\":self.arms[ind],\n",
    "                    \"pulls\":self.pulls[ind],\n",
    "                    \"reward\":self.reward[ind],\n",
    "                    \"value\":self.values[ind]\n",
    "                    }\n",
    "            return arm\n",
    "        else:\n",
    "            raise KeyError(\"Arm is not found in this bandit\")\n",
    "\n",
    "    def __str__(self):\n",
    "        output = '%s  ' % self.__class__.__name__\n",
    "        output += '; '.join(['%s:%s' % (key, val) for key, val in self.__dict__.items()])\n",
    "        return output\n",
    "\n",
    "class EpsilonGreedyBandit(Bandit):\n",
    "    \"\"\"Epsilon Greedy Bandit implementation.  Aggressively favors the present winner.\n",
    "    Will assign winning arm 1.0 - epsilon of the time, uniform random between arms\n",
    "    epsilon % of the time.\n",
    "    Will \"exploit\" the present winner more often with lower values of epsilon, \"explore\"\n",
    "    other candidates more often with higher values of epsilon.\n",
    "    :param epsilon: The percentage of the time to \"explore\" other arms, E.G a value of\n",
    "                    0.1 will perform random assignment for %10 of traffic\n",
    "    :type epsilon: float\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        super(EpsilonGreedyBandit, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def suggest_arm(self):\n",
    "        \"\"\"Get an arm according to the EpsilonGreedy Strategy\n",
    "        \"\"\"\n",
    "        random_determination = random()\n",
    "        if random_determination > self.epsilon:\n",
    "            key = self._ind_max()\n",
    "        else:\n",
    "            key = choice(self.arms)\n",
    "\n",
    "        return self[key]\n",
    "\n",
    "    def _ind_max(self):\n",
    "        return self.arms[self.confidence.index(max(self.confidence))]\n",
    "\n",
    "    def __str__(self):\n",
    "        return Bandit.__str__(self)\n",
    "\n",
    "    def __repr(self):\n",
    "        return Bandit.__str__(self)\n",
    "\n",
    "def all_same(items):\n",
    "    return all(x == items[0] for x in items)\n",
    "\n",
    "class NaiveStochasticBandit(Bandit):\n",
    "    \"\"\"A naive weighted random Bandit.  Favors the winner by giving it greater weight\n",
    "    in random selection.\n",
    "    Winner will eventually flatten out the losers if margin is great enough\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NaiveStochasticBandit, self).__init__()\n",
    "\n",
    "    def _compute_weights(self):\n",
    "        weights = []\n",
    "        for ind, n in enumerate(self.pulls):\n",
    "            reward = self.reward[ind]\n",
    "            try:\n",
    "                weights.append(1.0 * (float(reward)/float(n)))\n",
    "            except ZeroDivisionError:\n",
    "                weights.append(1.0/len(self.arms))\n",
    "        return weights\n",
    "\n",
    "    def suggest_arm(self):\n",
    "        \"\"\"Get an arm according to the Naive Stochastic Strategy\n",
    "        \"\"\"\n",
    "        weights = self._compute_weights()\n",
    "        random_determination = uniform(0.0, 1.0)\n",
    "\n",
    "        cum_weight = 0.0\n",
    "        for ind, weight in enumerate(weights):\n",
    "            cum_weight += weight\n",
    "            if cum_weight > random_determination:\n",
    "                return self[self.arms[ind]]\n",
    "        return self[self.arms[0]]\n",
    "\n",
    "\n",
    "class SoftmaxBandit(NaiveStochasticBandit):\n",
    "\n",
    "    def __init__(self, tau=0.1):\n",
    "        super(SoftmaxBandit, self).__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def _compute_weights(self):\n",
    "        weights = []\n",
    "        total_reward = sum([exp(x / self.tau) for x in self.confidence])\n",
    "        for ind, n in enumerate(self.pulls):\n",
    "            weights.append(exp(self.confidence[ind] / self.tau) / total_reward)\n",
    "        return weights\n",
    "\n",
    "\n",
    "class AnnealingSoftmaxBandit(SoftmaxBandit):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AnnealingSoftmaxBandit, self).__init__()\n",
    "        self.tau = 1\n",
    "\n",
    "    def _compute_weights(self):\n",
    "        t = sum(self.pulls) + 1\n",
    "        self.tau = 1 / log(t +  0.0000001)\n",
    "\n",
    "        weights = []\n",
    "        total_reward = sum([exp(x / self.tau) for x in self.confidence])\n",
    "        for ind, n in enumerate(self.pulls):\n",
    "            weights.append(exp(self.confidence[ind] / self.tau) / total_reward)\n",
    "        return weights\n",
    "\n",
    "class ThompsonBandit(NaiveStochasticBandit):\n",
    "\n",
    "    def __init__(self, prior=(1.0,1.0)):\n",
    "        super(ThompsonBandit, self).__init__()\n",
    "        self.prior = prior\n",
    "\n",
    "    def _compute_weights(self):\n",
    "        sampled_theta = []\n",
    "        for ind, n in enumerate(self.arms):\n",
    "            dist = betavariate(self.prior[0] + self.reward[ind], self.prior[1]+self.pulls[ind]-self.reward[ind])\n",
    "            sampled_theta += [dist]\n",
    "        return sampled_theta\n",
    "\n",
    "    def suggest_arm(self):\n",
    "        weights = self._compute_weights()\n",
    "        return self[self.arms[weights.index(max(weights))]]\n",
    "\n",
    "    def reward_arm(self, arm_id, reward):\n",
    "        if reward != 1.0:\n",
    "            reward = 1.0\n",
    "        super(ThompsonBandit, self).reward_arm(arm_id, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arms=['df','d']\n",
    "arm_id='d'\n",
    "arms.index(arm_id)\n",
    "yy=[1,2]\n",
    "list(set(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mab(object):\n",
    "    \"\"\"State object for mab extension\n",
    "    \"\"\"\n",
    "    def __init__(self, app):\n",
    "        self.bandits = {}\n",
    "        self.reward_endpts = []\n",
    "        self.pull_endpts = []\n",
    "        self.debug_headers = app.config.get('MAB_DEBUG_HEADERS', True)\n",
    "        self.cookie_name = app.config.get('MAB_COOKIE_NAME', \"MAB\")\n",
    "        self.bandit_storage = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_arm(bandit):\n",
    "    \"\"\"Route decorator for registering an impression conveinently\n",
    "    :param bandit: The bandit/experiment to register for\n",
    "    :type bandit: string\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        #runs @ service init\n",
    "        if not hasattr(func, 'bandits'):\n",
    "            func.bandits = []\n",
    "        func.bandits.append(bandit)\n",
    "\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            #runs at endpoint hit\n",
    "            add_args = []\n",
    "            for bandit in func.bandits:\n",
    "                #Fetch from request first here?\n",
    "                arm_id, arm_value = suggest_arm_for(bandit)\n",
    "                add_args.append((bandit, arm_value))\n",
    "            kwargs.update(add_args)\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "def reward_endpt(bandit, reward_val=1):\n",
    "    \"\"\"Route decorator for rewards.\n",
    "    :param bandit: The bandit/experiment to register rewards\n",
    "                   for using arm found in cookie.\n",
    "    :type bandit: string\n",
    "    :param reward: The amount of reward this endpoint should\n",
    "                   give its winning arm\n",
    "    :type reward: float\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        if not hasattr(func, 'rewards'):\n",
    "            func.rewards = []\n",
    "        func.rewards.append((bandit, reward_val))\n",
    "\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for bandit, reward_amt in func.rewards:\n",
    "                if bandit in request.bandits.keys():\n",
    "                    request.bandits_reward.add((bandit, request.bandits[bandit], reward_amt))\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "def suggest_arm_for(key):\n",
    "    \"\"\"Get an experimental outcome by id.  The primary way the implementor interfaces with their\n",
    "    experiments.\n",
    "    Suggests arms if not in cookie, using cookie val if present\n",
    "    :param key: The bandit/experiment to get a suggested arm for\n",
    "    :type key: string\n",
    "    :param also_pull: Should we register a pull/impression at the same time as suggesting\n",
    "    :raises KeyError: in case requested experiment does not exist\n",
    "    \"\"\"\n",
    "    app = current_app\n",
    "    try:\n",
    "        #Try to get the selected bandits from cookie\n",
    "        arm = app.extensions['mab'].bandits[key][request.bandits[key]]\n",
    "        return arm[\"id\"], arm[\"value\"]\n",
    "    except (AttributeError, TypeError, KeyError) as err:\n",
    "        #Assign an arm for a new client\n",
    "        try:\n",
    "            arm = app.extensions['mab'].bandits[key].suggest_arm()\n",
    "            request.bandits[key] = arm[\"id\"]\n",
    "            request.bandits_save = True\n",
    "            return arm[\"id\"], arm[\"value\"]\n",
    "        except KeyError:\n",
    "            raise MABConfigException(\"Bandit %s not found\" % key)\n",
    "\n",
    "def add_bandit(app, name, bandit=None):\n",
    "    \"\"\"Attach a bandit for an experiment\n",
    "    :param name: The name of the experiment, will be used for lookups\n",
    "    :param bandit: The bandit to use for this experiment\n",
    "    :type bandit: Bandit\n",
    "    \"\"\"\n",
    "    saved_bandits = app.extensions['mab'].bandit_storage.load()\n",
    "    if name in saved_bandits.keys():\n",
    "        app.extensions['mab'].bandits[name] = saved_bandits[name]\n",
    "    else:\n",
    "        app.extensions['mab'].bandits[name] = bandit\n",
    "\n",
    "class MABConfigException(Exception):\n",
    "    \"\"\"Raised when internal state in MAB setup is invalid\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue': 0.93, 'green': 0.2, 'red': 0.2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MonteCarloTest(object):\n",
    "    \"\"\"Tests to ensure that over many iterations, a winner\n",
    "    eventually converges\"\"\"\n",
    "    def __init__(self):\n",
    "        self.true_arm_probs = dict(green=0.2, red=0.2, blue=0.93)\n",
    "    def draw(self, arm_name):\n",
    "        if random.random() > self.true_arm_probs[arm_name]:\n",
    "            return 0.0\n",
    "        return 1.0\n",
    "\n",
    "    def run_algo(self, bandit, num_sims, horizon):\n",
    "        chosen_arms = [0.0 for i in range(num_sims * horizon)]\n",
    "        rewards = [0.0 for i in range(num_sims * horizon)]\n",
    "        cumulative_rewards = [0.0 for i in range(num_sims * horizon)]\n",
    "        sim_nums = [0.0 for i in range(num_sims * horizon)]\n",
    "        times = [0.0 for i in range(num_sims * horizon)]\n",
    "\n",
    "        for sim in range(num_sims):\n",
    "            sim = sim + 1\n",
    "\n",
    "            for t in range(horizon):\n",
    "                t = t + 1\n",
    "                index = (sim - 1) * horizon + t - 1\n",
    "                sim_nums[index] = sim\n",
    "                times[index] = t\n",
    "\n",
    "                chosen_arm = bandit.suggest_arm()\n",
    "                chosen_arms[index] = chosen_arm['id']\n",
    "                bandit.pull_arm(chosen_arm['id'])\n",
    "                reward = self.draw(chosen_arm['id'])\n",
    "                rewards[index] = reward\n",
    "\n",
    "                if t == 1:\n",
    "                    cumulative_rewards[index] = reward\n",
    "                else:\n",
    "                    cumulative_rewards[index] = cumulative_rewards[index - 1] + reward\n",
    "\n",
    "                if reward:\n",
    "                    bandit.reward_arm(chosen_arm['id'], reward)\n",
    "\n",
    "        return [sim_nums, times, chosen_arms, rewards, cumulative_rewards]\n",
    "\n",
    "    def save_results(self, results, output_stream):\n",
    "        for sim in range(len(results[0])):\n",
    "            output_stream.write(\"  \".join([str(results[j][sim]) for j in range(len(results))]) + \"\\n\")\n",
    "            sys.stdout.flush()\n",
    "import flask_mab.bandits as bandits\n",
    "\n",
    "def makeBandit(bandit_type,**kwargs):\n",
    "    bandit_cls = getattr(bandits, bandit_type)\n",
    "    bandit = bandit_cls(**kwargs)\n",
    "    bandit.add_arm(\"green\",\"#00FF00\")\n",
    "    bandit.add_arm(\"red\",\"#FF0000\")\n",
    "    bandit.add_arm(\"blue\",\"#0000FF\")\n",
    "    return bandit\n",
    "bandit_name = 'EpsilonGreedyBandit'\n",
    "\n",
    "true_arm_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_exp = makeBandit(bandit_name, epsilon=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flask_mab.bandits.EpsilonGreedyBandit at 0x1094bd810>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.69192814827\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "t1=time.time()\n",
    "exp=MonteCarloTest()\n",
    "results = exp.run_algo(makeBandit('EpsilonGreedyBandit', epsilon=0.3), 3000, 250)\n",
    "print time.time()-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results[4])#[100]  SoftmaxBandit,AnnealingSoftmaxBandit,ThompsonBandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.00602483749\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "exp=MonteCarloTest()\n",
    "results = exp.run_algo(makeBandit('SoftmaxBandit', tau=0.3), 3000, 250)\n",
    "print time.time()-t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.53866410255\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "exp=MonteCarloTest()\n",
    "results = exp.run_algo(makeBandit('AnnealingSoftmaxBandit', tau=0.3), 3000, 250)\n",
    "print time.time()-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5467870235\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "exp=MonteCarloTest()\n",
    "results = exp.run_algo(makeBandit('ThompsonBandit'), 3000, 250)\n",
    "print time.time()-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "whee!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e5f0f326e99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmyhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOldStyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-e5f0f326e99f>\u001b[0m in \u001b[0;36mmyhasattr\u001b[0;34m(obj, name, _marker)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimplement\u001b[0m \u001b[0mour\u001b[0m \u001b[0mown\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_marker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_marker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mOldStyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e5f0f326e99f>\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"whee!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: whee!"
     ]
    }
   ],
   "source": [
    "def myhasattr(obj, name, _marker=object()):\n",
    "    \"\"\"Make sure we don't mask exceptions like hasattr().\n",
    "    We don't want exceptions other than AttributeError to be masked,\n",
    "    since that too often masks other programming errors.\n",
    "    Three-argument getattr() doesn't mask those, so we use that to\n",
    "    implement our own hasattr() replacement.\n",
    "    \"\"\"\n",
    "    return getattr(obj, name, _marker) is not _marker\n",
    "class OldStyle(object):\n",
    "    bar = \"bar\"\n",
    "    def __getattr__(self, name):\n",
    "        if name == \"error\":\n",
    "            raise ValueError(\"whee!\")\n",
    "        else:\n",
    "            raise AttributeError(name)\n",
    "myhasattr(OldStyle(), \"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
