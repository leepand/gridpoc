{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_status.py\n"
     ]
    }
   ],
   "source": [
    "%%file run_status.py\n",
    "class RunStatus(object):\n",
    "    \"\"\"Enum for status of an :py:class:`mlflow.entities.Run`.\"\"\"\n",
    "    RUNNING, SCHEDULED, FINISHED, FAILED = range(1, 5)\n",
    "    _STRING_TO_STATUS = {\n",
    "        \"RUNNING\": RUNNING,\n",
    "        \"SCHEDULED\": SCHEDULED,\n",
    "        \"FINISHED\": FINISHED,\n",
    "        \"FAILED\": FAILED,\n",
    "    }\n",
    "    _STATUS_TO_STRING = {value: key for key, value in _STRING_TO_STATUS.items()}\n",
    "    _TERMINATED_STATUSES = set([FINISHED, FAILED])\n",
    "\n",
    "    @staticmethod\n",
    "    def from_string(status_str):\n",
    "        if status_str not in RunStatus._STRING_TO_STATUS:\n",
    "            raise Exception(\n",
    "                \"Could not get run status corresponding to string %s. Valid run \"\n",
    "                \"status strings: %s\" % (status_str, list(RunStatus._STRING_TO_STATUS.keys())))\n",
    "        return RunStatus._STRING_TO_STATUS[status_str]\n",
    "\n",
    "    @staticmethod\n",
    "    def to_string(status):\n",
    "        if status not in RunStatus._STATUS_TO_STRING:\n",
    "            raise Exception(\"Could not get string corresponding to run status %s. Valid run \"\n",
    "                            \"statuses: %s\" % (status, list(RunStatus._STATUS_TO_STRING.keys())))\n",
    "        return RunStatus._STATUS_TO_STRING[status]\n",
    "\n",
    "    @staticmethod\n",
    "    def is_terminated(status):\n",
    "        return status in RunStatus._TERMINATED_STATUSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing spinner.py\n"
     ]
    }
   ],
   "source": [
    "%%file spinner.py\n",
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "import threading\n",
    "\n",
    "\n",
    "class Spinner:\n",
    "    def __init__(self, delay=0.1):\n",
    "        self.spinner_generator = itertools.cycle(['-', '/', '|', '\\\\'])\n",
    "        if delay and float(delay): self.delay = delay\n",
    "\n",
    "    def spinner_task(self):\n",
    "        while self.busy:\n",
    "            sys.stdout.write(next(self.spinner_generator))\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(self.delay)\n",
    "            sys.stdout.write('\\b')\n",
    "\n",
    "    def start(self):\n",
    "        self.busy = True\n",
    "        threading.Thread(target=self.spinner_task).start()\n",
    "        return True\n",
    "\n",
    "    def stop(self):\n",
    "        self.busy = False\n",
    "        time.sleep(self.delay)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submitted_run.py\n"
     ]
    }
   ],
   "source": [
    "%%file submitted_run.py\n",
    "from abc import abstractmethod\n",
    "from .spinner import Spinner\n",
    "import os\n",
    "import signal\n",
    "import logging\n",
    "from .run_status import RunStatus\n",
    "#from mlflow.entities import RunStatus\n",
    "\n",
    "\n",
    "_logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class SubmittedRun(object):\n",
    "    \"\"\"\n",
    "    Wrapper around an MLflow project run (e.g. a subprocess running an entry point\n",
    "    command or a Databricks job run) and exposing methods for waiting on and cancelling the run.\n",
    "    This class defines the interface that the MLflow project runner uses to manage the lifecycle\n",
    "    of runs launched in different environments (e.g. runs launched locally or on Databricks).\n",
    "    ``SubmittedRun`` is not thread-safe. That is, concurrent calls to wait() / cancel()\n",
    "    from multiple threads may inadvertently kill resources (e.g. local processes) unrelated to the\n",
    "    run.\n",
    "    NOTE:\n",
    "        Subclasses of ``SubmittedRun`` must expose a ``run_id`` member containing the\n",
    "        run's MLflow run ID.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def wait(self):\n",
    "        \"\"\"\n",
    "        Wait for the run to finish, returning True if the run succeeded and false otherwise. Note\n",
    "        that in some cases (e.g. remote execution on Databricks), we may wait until the remote job\n",
    "        completes rather than until the MLflow run completes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_status(self):\n",
    "        \"\"\"\n",
    "        Get status of the run.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def cancel(self):\n",
    "        \"\"\"\n",
    "        Cancel the run (interrupts the command subprocess, cancels the Databricks run, etc) and\n",
    "        waits for it to terminate. The MLflow run status may not be set correctly\n",
    "        upon run cancellation.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def run_id(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class LocalSubmittedRun(SubmittedRun):\n",
    "    \"\"\"\n",
    "    Instance of ``SubmittedRun`` corresponding to a subprocess launched to run an entry point\n",
    "    command locally.\n",
    "    \"\"\"\n",
    "    def __init__(self, run_id, command_proc):\n",
    "        super(LocalSubmittedRun, self).__init__()\n",
    "\n",
    "        self._run_id = run_id\n",
    "        self.spinner = Spinner()\n",
    "        try:\n",
    "            self.spinner.start()\n",
    "            self.command_proc = command_proc\n",
    "        finally:\n",
    "            self.spinner.stop()\n",
    "\n",
    "    @property\n",
    "    def run_id(self):\n",
    "        return self._run_id\n",
    "\n",
    "    def wait(self):\n",
    "        return self.command_proc.wait() == 0\n",
    "\n",
    "    def cancel(self):\n",
    "        # Interrupt child process if it hasn't already exited\n",
    "        if self.command_proc.poll() is None:\n",
    "            # Kill the the process tree rooted at the child if it's the leader of its own process\n",
    "            # group, otherwise just kill the child\n",
    "            try:\n",
    "                if self.command_proc.pid == os.getpgid(self.command_proc.pid):\n",
    "                    os.killpg(self.command_proc.pid, signal.SIGTERM)\n",
    "                else:\n",
    "                    self.command_proc.terminate()\n",
    "            except OSError:\n",
    "                # The child process may have exited before we attempted to terminate it, so we\n",
    "                # ignore OSErrors raised during child process termination\n",
    "                _logger.info(\n",
    "                    \"Failed to terminate child process (PID %s) corresponding to Arthur.io \"\n",
    "                    \"run with ID %s. The process may have already exited.\",\n",
    "                    self.command_proc.pid, self._run_id)\n",
    "            self.command_proc.wait()\n",
    "\n",
    "    def _get_status(self):\n",
    "        exit_code = self.command_proc.poll()\n",
    "        if exit_code is None:\n",
    "            return RunStatus.RUNNING\n",
    "        if exit_code == 0:\n",
    "            return RunStatus.FINISHED\n",
    "        return RunStatus.FAILED\n",
    "\n",
    "    def get_status(self):\n",
    "        return RunStatus.to_string(self._get_status()),self.command_proc.pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting store/exp_file_process.py\n"
     ]
    }
   ],
   "source": [
    "%%file store/exp_file_process.py\n",
    "import os,sys\n",
    "import yaml\n",
    "from .file_utils import (build_path,exists,mkdir,is_directory,write_yaml,\n",
    "                        find,read_yaml,list_subdirs,mv,get_parent_dir,_copy_file_or_tree)\n",
    "from Arthur.core.utils.experiment.experiment import Experiment\n",
    "from Arthur.core.utils.store.abstract_store import AbstractStore\n",
    "from Arthur.core.utils.env import get_env\n",
    "from Arthur.core.utils.entities.ViewType import ViewType\n",
    "from Arthur.core.utils.experiment.validation import _validate_run_id,_validate_experiment_id\n",
    "PY2 = (sys.version_info.major == 2)\n",
    "if PY2:\n",
    "    from backports import tempfile\n",
    "else:\n",
    "    import tempfile\n",
    "\n",
    "_TRACKING_DIR_ENV_VAR = \"ARTHUR_TRACKING_DIR\"\n",
    "\n",
    "\n",
    "def _default_root_dir():\n",
    "    return get_env(_TRACKING_DIR_ENV_VAR) or os.path.abspath(\"arthur_runs\")\n",
    "\n",
    "\n",
    "class FileStore(AbstractStore):\n",
    "    TRASH_FOLDER_NAME = \".trash\"\n",
    "    ARTIFACTS_FOLDER_NAME = \"artifacts\"\n",
    "    METRICS_FOLDER_NAME = \"metrics\"\n",
    "    PARAMS_FOLDER_NAME = \"params\"\n",
    "    TAGS_FOLDER_NAME = \"tags\"\n",
    "    META_DATA_FILE_NAME = \"meta.yaml\"\n",
    "\n",
    "    def __init__(self, root_directory=None, artifact_root_uri=None):\n",
    "        \"\"\"\n",
    "        Create a new FileStore with the given root directory and a given default artifact root URI.\n",
    "        \"\"\"\n",
    "        super(FileStore, self).__init__()\n",
    "        self.root_directory = root_directory or _default_root_dir()\n",
    "        self.artifact_root_uri = artifact_root_uri or self.root_directory\n",
    "        self.trash_folder = build_path(self.root_directory, FileStore.TRASH_FOLDER_NAME)\n",
    "        # Create root directory if needed\n",
    "        if not exists(self.root_directory):\n",
    "            mkdir(self.root_directory)\n",
    "            #self._create_experiment_with_id(name=\"Default\",\n",
    "            #                                experiment_id=Experiment.DEFAULT_EXPERIMENT_ID,\n",
    "            #                                artifact_uri=None)\n",
    "        # Create trash folder if needed\n",
    "        if not exists(self.trash_folder):\n",
    "            mkdir(self.trash_folder)\n",
    "    def _check_root_dir(self):\n",
    "        \"\"\"\n",
    "        Run checks before running directory operations.\n",
    "        \"\"\"\n",
    "        if not exists(self.root_directory):\n",
    "            raise Exception(\"'%s' does not exist.\" % self.root_directory)\n",
    "        if not is_directory(self.root_directory):\n",
    "            raise Exception(\"'%s' is not a directory.\" % self.root_directory)\n",
    "    def _get_experiment_path(self, experiment_id, view_type=ViewType.ALL):\n",
    "        parents = []\n",
    "        if view_type == ViewType.ACTIVE_ONLY or view_type == ViewType.ALL:\n",
    "            parents.append(self.root_directory)\n",
    "        if view_type == ViewType.DELETED_ONLY or view_type == ViewType.ALL:\n",
    "            parents.append(self.trash_folder)\n",
    "        for parent in parents:\n",
    "            exp_list = find(parent, str(experiment_id), full_path=True)\n",
    "            if len(exp_list) > 0:\n",
    "                return exp_list[0]\n",
    "        return None\n",
    "       \n",
    "    def _get_run_dir(self, experiment_id, run_uuid):\n",
    "        #_validate_run_id(run_uuid)\n",
    "        if not self._has_experiment(experiment_id):\n",
    "            return None\n",
    "        return build_path(self._get_experiment_path(experiment_id), run_uuid)\n",
    "    def _get_artifact_dir(self, experiment_id, run_uuid):\n",
    "        #_validate_run_id(run_uuid)\n",
    "        artifacts_dir = build_path(self.get_experiment(experiment_id).artifact_location,\n",
    "                                   run_uuid,\n",
    "                                   FileStore.ARTIFACTS_FOLDER_NAME)\n",
    "        return artifacts_dir\n",
    "    def _get_active_experiments(self, full_path=False):\n",
    "        exp_list = list_subdirs(self.root_directory, full_path)\n",
    "        return [exp for exp in exp_list if not exp.endswith(FileStore.TRASH_FOLDER_NAME)]\n",
    "\n",
    "    def _get_deleted_experiments(self, full_path=False):\n",
    "        return list_subdirs(self.trash_folder, full_path)\n",
    "\n",
    "    def list_experiments(self, view_type=ViewType.ACTIVE_ONLY):\n",
    "        self._check_root_dir()\n",
    "        rsl = []\n",
    "        if view_type == ViewType.ACTIVE_ONLY or view_type == ViewType.ALL:\n",
    "            rsl += self._get_active_experiments(full_path=False)\n",
    "        if view_type == ViewType.DELETED_ONLY or view_type == ViewType.ALL:\n",
    "            rsl += self._get_deleted_experiments(full_path=False)\n",
    "        experiments = []\n",
    "        for exp_id in rsl:\n",
    "            try:\n",
    "                # trap and warn known issues, will raise unexpected exceptions to caller\n",
    "                experiment = self._get_experiment(exp_id, view_type)\n",
    "                if experiment:\n",
    "                    experiments.append(experiment)\n",
    "            except MissingConfigException as rnfe:\n",
    "                # Trap malformed experiments and log warnings.\n",
    "                logging.warning(\"Malformed experiment '%s'. Detailed error %s\",\n",
    "                                str(exp_id), str(rnfe), exc_info=True)\n",
    "        return experiments\n",
    "\n",
    "    def _create_experiment_with_id(self, project_path,name, experiment_id, artifact_uri=None):\n",
    "        self._check_root_dir()\n",
    "        meta_dir = mkdir(self.root_directory, str(experiment_id))\n",
    "        artifact_uri = artifact_uri or build_path(self.artifact_root_uri, str(experiment_id))\n",
    "        experiment = Experiment(experiment_id, name, artifact_uri, Experiment.ACTIVE_LIFECYCLE)\n",
    "        write_yaml(meta_dir, FileStore.META_DATA_FILE_NAME, dict(experiment))\n",
    "        #copy project files to experiment path from web source\n",
    "        _copy_file_or_tree(project_path,artifact_uri,dst_dir=name)\n",
    "        return experiment_id\n",
    "\n",
    "    def create_experiment(self, project_path,name, artifact_location=None):\n",
    "        self._check_root_dir()\n",
    "        if name is None or name == \"\":\n",
    "            raise Exception(\"Invalid experiment name '%s'\" % name)\n",
    "        experiment = self.get_experiment_by_name(name)\n",
    "        if experiment is not None:\n",
    "            raise Exception(\"Experiment '%s' already exists.\" % experiment.name)\n",
    "        # Get all existing experiments and find the one with largest ID.\n",
    "        # len(list_all(..)) would not work when experiments are deleted.\n",
    "        experiments_ids = [e.experiment_id for e in self.list_experiments(ViewType.ALL)]\n",
    "        experiment_id = max(experiments_ids) + 1 if experiments_ids else 0\n",
    "        return self._create_experiment_with_id(project_path,name, experiment_id, artifact_location)\n",
    "\n",
    "    def _has_experiment(self, experiment_id):\n",
    "        return self._get_experiment_path(experiment_id) is not None \n",
    "    def get_experiment(self, experiment_id):\n",
    "        \"\"\"\n",
    "        Fetches the experiment. This will search for active as well as deleted experiments.\n",
    "        :param experiment_id: Integer id for the experiment\n",
    "        :return: A single Experiment object if it exists, otherwise raises an Exception.\n",
    "        \"\"\"\n",
    "        experiment = self._get_experiment(experiment_id)\n",
    "        if experiment is None:\n",
    "            raise Exception(\"Experiment '%s' does not exist.\" % experiment_id)\n",
    "        return experiment\n",
    "    def get_experiment_by_name(self, name):\n",
    "        self._check_root_dir()\n",
    "        for experiment in self.list_experiments(ViewType.ALL):\n",
    "            if experiment.name == name:\n",
    "                return experiment\n",
    "        return None\n",
    "    def _get_experiment(self, experiment_id, view_type=ViewType.ALL):\n",
    "        self._check_root_dir()\n",
    "        _validate_experiment_id(experiment_id)\n",
    "        experiment_dir = self._get_experiment_path(experiment_id, view_type)\n",
    "        if experiment_dir is None:\n",
    "            raise Exception(\"Could not find experiment with ID %s\" % experiment_id)\n",
    "        meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
    "        if experiment_dir.startswith(self.trash_folder):\n",
    "            meta['lifecycle_stage'] = Experiment.DELETED_LIFECYCLE\n",
    "        else:\n",
    "            meta['lifecycle_stage'] = Experiment.ACTIVE_LIFECYCLE\n",
    "        experiment = Experiment.from_dictionary(meta)\n",
    "        if int(experiment_id) != experiment.experiment_id:\n",
    "            logging.warning(\"Experiment ID mismatch for exp %s. ID recorded as '%s' in meta data. \"\n",
    "                            \"Experiment will be ignored.\",\n",
    "                            str(experiment_id), str(experiment.experiment_id), exc_info=True)\n",
    "            return None\n",
    "        return experiment\n",
    "    def delete_experiment(self, experiment_id):\n",
    "        experiment_dir = self._get_experiment_path(experiment_id, ViewType.ACTIVE_ONLY)\n",
    "        if experiment_dir is None:\n",
    "            raise Exception(\"Could not find experiment with ID %s\" % experiment_id)\n",
    "        mv(experiment_dir, self.trash_folder)\n",
    "    def restore_experiment(self, experiment_id):\n",
    "        experiment_dir = self._get_experiment_path(experiment_id, ViewType.DELETED_ONLY)\n",
    "        if experiment_dir is None:\n",
    "            raise Exception(\"Could not find deleted experiment with ID %d\" % experiment_id)\n",
    "        conflict_experiment = self._get_experiment_path(experiment_id, ViewType.ACTIVE_ONLY)\n",
    "        if conflict_experiment is not None:\n",
    "            raise Exception(\n",
    "                    \"Cannot restore eperiment with ID %d. \"\n",
    "                    \"An experiment with same ID already exists.\" % experiment_id)\n",
    "        mv(experiment_dir, self.root_directory)\n",
    "    def rename_experiment(self, experiment_id, new_name):\n",
    "        meta_dir = os.path.join(self.root_directory, str(experiment_id))\n",
    "        # if experiment is malformed, will raise error\n",
    "        experiment = self._get_experiment(experiment_id)\n",
    "        if experiment is None:\n",
    "            raise Exception(\"Experiment '%s' does not exist.\" % experiment_id)\n",
    "        experiment._set_name(new_name)\n",
    "        if experiment.lifecycle_stage != Experiment.ACTIVE_LIFECYCLE:\n",
    "            raise Exception(\"Cannot rename experiment in non-active lifecycle stage.\"\n",
    "                            \" Current stage: %s\" % experiment.lifecycle_stage)\n",
    "        write_yaml(meta_dir, FileStore.META_DATA_FILE_NAME, dict(experiment), overwrite=True)\n",
    "    def _find_experiment_folder(self, run_path):\n",
    "        \"\"\"\n",
    "        Given a run path, return the parent directory for its experiment.\n",
    "        \"\"\"\n",
    "        parent = get_parent_dir(run_path)\n",
    "        if os.path.basename(parent) == FileStore.TRASH_FOLDER_NAME:\n",
    "            return get_parent_dir(parent)\n",
    "        return parent\n",
    "#test=FileStore()\n",
    "#test._get_experiment_path(0)\n",
    "#test._get_run_dir(0,'110')\n",
    "#test._get_artifact_dir(0,'110')\n",
    "#test._get_active_experiments()\n",
    "#test._get_deleted_experiments()\n",
    "#test.list_experiments()\n",
    "#test._create_experiment_with_id('leepand',4)\n",
    "#test.create_experiment('arthur')\n",
    "#test.delete_experiment(4)\n",
    "#test.restore_experiment(4)\n",
    "#test.rename_experiment(5,'arthur_new')\n",
    "#test._find_experiment_folder('../')\n",
    "#test.list_experiments()\n",
    "#test.create_experiment('../tttt','arthur')\n",
    "#_copy_file_or_tree('../tttt','arthur_runs/',dst_dir='code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing experiment.py\n"
     ]
    }
   ],
   "source": [
    "%%file experiment.py\n",
    "from ._arthur_object import _ArthurObject\n",
    "\n",
    "\n",
    "class Experiment(_ArthurObject):\n",
    "    \"\"\"\n",
    "    Experiment object.\n",
    "    \"\"\"\n",
    "    DEFAULT_EXPERIMENT_ID = 0\n",
    "    ACTIVE_LIFECYCLE = 'active'\n",
    "    DELETED_LIFECYCLE = 'deleted'\n",
    "\n",
    "    def __init__(self, experiment_id, name, artifact_location, lifecycle_stage):\n",
    "        super(Experiment, self).__init__()\n",
    "        self._experiment_id = experiment_id\n",
    "        self._name = name\n",
    "        self._artifact_location = artifact_location\n",
    "        self._lifecycle_stage = lifecycle_stage\n",
    "\n",
    "    @property\n",
    "    def experiment_id(self):\n",
    "        \"\"\"Integer ID of the experiment.\"\"\"\n",
    "        return self._experiment_id\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"String name of the experiment.\"\"\"\n",
    "        return self._name\n",
    "\n",
    "    def _set_name(self, new_name):\n",
    "        self._name = new_name\n",
    "\n",
    "    @property\n",
    "    def artifact_location(self):\n",
    "        \"\"\"String corresponding to the root artifact URI for the experiment.\"\"\"\n",
    "        return self._artifact_location\n",
    "\n",
    "    @property\n",
    "    def lifecycle_stage(self):\n",
    "        \"\"\"Lifecycle stage of the experiment. Can either be 'active' or 'deleted'.\"\"\"\n",
    "        return self._lifecycle_stage\n",
    "\n",
    "    @classmethod\n",
    "    def from_proto(cls, proto):\n",
    "        return cls(proto.experiment_id, proto.name, proto.artifact_location, proto.lifecycle_stage)\n",
    "\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def _properties(cls):\n",
    "        # TODO: Hard coding this list of props for now. There has to be a clearer way...\n",
    "        return [\"experiment_id\", \"name\", \"artifact_location\", \"lifecycle_stage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing env.py\n"
     ]
    }
   ],
   "source": [
    "%%file env.py\n",
    "import os\n",
    "\n",
    "\n",
    "def get_env(variable_name):\n",
    "    return os.environ.get(variable_name)\n",
    "\n",
    "\n",
    "def unset_variable(variable_name):\n",
    "    if variable_name in os.environ:\n",
    "        del os.environ[variable_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing experiment/validation.py\n"
     ]
    }
   ],
   "source": [
    "%%file experiment/validation.py\n",
    "\"\"\"\n",
    "Utilities for validating user inputs such as metric names and parameter names.\n",
    "\"\"\"\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "# Regex for valid run IDs: must be a 32-character hex string.\n",
    "_RUN_ID_REGEX = re.compile(r\"^[0-9a-f]{32}$\")\n",
    "def _validate_run_id(run_id):\n",
    "    \"\"\"Check that `run_id` is a valid run ID and raise an exception if it isn't.\"\"\"\n",
    "    if _RUN_ID_REGEX.match(run_id) is None:\n",
    "        raise Exception(\"Invalid run ID: '%s'\" % run_id)\n",
    "\n",
    "\n",
    "def _validate_experiment_id(exp_id):\n",
    "    \"\"\"Check that `experiment_id`is a valid integer and raise an exception if it isn't.\"\"\"\n",
    "    try:\n",
    "        int(exp_id)\n",
    "    except ValueError:\n",
    "        raise Exception(\"Invalid experiment ID: '%s'\" % exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing _arthur_object.py\n"
     ]
    }
   ],
   "source": [
    "%%file _arthur_object.py\n",
    "from abc import abstractmethod\n",
    "import pprint\n",
    "\n",
    "\n",
    "class _ArthurObject(object):\n",
    "    def __iter__(self):\n",
    "        # Iterate through list of properties and yield as key -> value\n",
    "        for prop in self._properties():\n",
    "            yield prop, self.__getattribute__(prop)\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def _properties(cls):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_proto(cls, proto):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def from_dictionary(cls, the_dict):\n",
    "        filtered_dict = {key: value for key, value in the_dict.items() if key in cls._properties()}\n",
    "        return cls(**filtered_dict)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return to_string(self)\n",
    "\n",
    "\n",
    "def to_string(obj):\n",
    "    return _ArthurObjectPrinter().to_string(obj)\n",
    "\n",
    "\n",
    "def get_classname(obj):\n",
    "    return type(obj).__name__\n",
    "\n",
    "\n",
    "class _ArthurObjectPrinter(object):\n",
    "    _MAX_LIST_LEN = 2\n",
    "\n",
    "    def __init__(self):\n",
    "        super(_ArthurObjectPrinter, self).__init__()\n",
    "        self.printer = pprint.PrettyPrinter()\n",
    "\n",
    "    def to_string(self, obj):\n",
    "        if isinstance(obj, _MLflowObject):\n",
    "            return \"<%s: %s>\" % (get_classname(obj), self._entity_to_string(obj))\n",
    "        # Handle nested lists inside MLflow entities (e.g. lists of metrics/params)\n",
    "        if isinstance(obj, list):\n",
    "            res = [self.to_string(elem) for elem in obj[:self._MAX_LIST_LEN]]\n",
    "            if len(obj) > self._MAX_LIST_LEN:\n",
    "                res.append(\"...\")\n",
    "            return \"[%s]\" % \", \".join(res)\n",
    "        return self.printer.pformat(obj)\n",
    "\n",
    "    def _entity_to_string(self, entity):\n",
    "        return \", \".join([\"%s=%s\" % (key, self.to_string(value)) for key, value in entity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing store/file_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%file store/file_utils.py\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "ENCODING = \"utf-8\"\n",
    "\n",
    "\n",
    "def is_directory(name):\n",
    "    return os.path.isdir(name)\n",
    "\n",
    "\n",
    "def is_file(name):\n",
    "    return os.path.isfile(name)\n",
    "\n",
    "\n",
    "def exists(name):\n",
    "    return os.path.exists(name)\n",
    "\n",
    "def build_path(*path_segments):\n",
    "    \"\"\" Returns the path formed by joining the passed-in path segments. \"\"\"\n",
    "    return os.path.join(*path_segments)\n",
    "\n",
    "\n",
    "def mkdir(root, name=None):  # noqa\n",
    "    \"\"\"\n",
    "    Make directory with name \"root/name\", or just \"root\" if name is None.\n",
    "    :param root: Name of parent directory\n",
    "    :param name: Optional name of leaf directory\n",
    "    :return: Path to created directory\n",
    "    \"\"\"\n",
    "    target = os.path.join(root, name) if name is not None else root\n",
    "    try:\n",
    "        if not exists(target):\n",
    "            os.makedirs(target)\n",
    "            return target\n",
    "    except OSError as e:\n",
    "        raise e\n",
    "def list_all(root, filter_func=lambda x: True, full_path=False):\n",
    "    \"\"\"\n",
    "    List all entities directly under 'dir_name' that satisfy 'filter_func'\n",
    "    :param root: Name of directory to start search\n",
    "    :param filter_func: function or lambda that takes path\n",
    "    :param full_path: If True will return results as full path including `root`\n",
    "    :return: list of all files or directories that satisfy the criteria.\n",
    "    \"\"\"\n",
    "    if not is_directory(root):\n",
    "        raise Exception(\"Invalid parent directory '%s'\" % root)\n",
    "    matches = [x for x in os.listdir(root) if filter_func(os.path.join(root, x))]\n",
    "    return [os.path.join(root, m) for m in matches] if full_path else matches\n",
    "\n",
    "\n",
    "def list_subdirs(dir_name, full_path=False):\n",
    "    \"\"\"\n",
    "    Equivalent to UNIX command:\n",
    "      ``find $dir_name -depth 1 -type d``\n",
    "    :param dir_name: Name of directory to start search\n",
    "    :param full_path: If True will return results as full path including `root`\n",
    "    :return: list of all directories directly under 'dir_name'\n",
    "    \"\"\"\n",
    "    return list_all(dir_name, os.path.isdir, full_path)\n",
    "\n",
    "\n",
    "def list_files(dir_name, full_path=False):\n",
    "    \"\"\"\n",
    "    Equivalent to UNIX command:\n",
    "      ``find $dir_name -depth 1 -type f``\n",
    "    :param dir_name: Name of directory to start search\n",
    "    :param full_path: If True will return results as full path including `root`\n",
    "    :return: list of all files directly under 'dir_name'\n",
    "    \"\"\"\n",
    "    return list_all(dir_name, os.path.isfile, full_path)\n",
    "\n",
    "def find(root, name, full_path=False):\n",
    "    \"\"\"\n",
    "    Search for a file in a root directory. Equivalent to:\n",
    "      ``find $root -name \"$name\" -depth 1``\n",
    "    :param root: Name of root directory for find\n",
    "    :param name: Name of file or directory to find directly under root directory\n",
    "    :param full_path: If True will return results as full path including `root`\n",
    "    :return: list of matching files or directories\n",
    "    \"\"\"\n",
    "    path_name = os.path.join(root, name)\n",
    "    return list_all(root, lambda x: x == path_name, full_path)\n",
    "        \n",
    "        \n",
    "def write_yaml(root, file_name, data, overwrite=False):\n",
    "    \"\"\"\n",
    "    Write dictionary data in yaml format.\n",
    "    :param root: Directory name.\n",
    "    :param file_name: Desired file name. Will automatically add .yaml extension if not given\n",
    "    :param data: data to be dumped as yaml format\n",
    "    :param overwrite: If True, will overwrite existing files\n",
    "    \"\"\"\n",
    "    if not exists(root):\n",
    "        raise MissingConfigException(\"Parent directory '%s' does not exist.\" % root)\n",
    "\n",
    "    file_path = os.path.join(root, file_name)\n",
    "    yaml_file_name = file_path if file_path.endswith(\".yaml\") else file_path + \".yaml\"\n",
    "\n",
    "    if exists(yaml_file_name) and not overwrite:\n",
    "        raise Exception(\"Yaml file '%s' exists as '%s\" % (file_path, yaml_file_name))\n",
    "\n",
    "    try:\n",
    "        with open(yaml_file_name, 'w') as yaml_file:\n",
    "            yaml.safe_dump(data, yaml_file, default_flow_style=False, allow_unicode=True)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "def read_yaml(root, file_name):\n",
    "    \"\"\"\n",
    "    Read data from yaml file and return as dictionary\n",
    "    :param root: Directory name\n",
    "    :param file_name: File name. Expects to have '.yaml' extension\n",
    "    :return: Data in yaml file as dictionary\n",
    "    \"\"\"\n",
    "    if not exists(root):\n",
    "        raise MissingConfigException(\n",
    "            \"Cannot read '%s'. Parent dir '%s' does not exist.\" % (file_name, root))\n",
    "\n",
    "    file_path = os.path.join(root, file_name)\n",
    "    if not exists(file_path):\n",
    "        raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as yaml_file:\n",
    "            return yaml.safe_load(yaml_file)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "def mv(target, new_parent):\n",
    "    shutil.move(target, new_parent)\n",
    "    \n",
    "def write_to(filename, data):\n",
    "    with codecs.open(filename, mode=\"w\", encoding=ENCODING) as handle:\n",
    "        handle.write(data)\n",
    "\n",
    "\n",
    "def append_to(filename, data):\n",
    "    with open(filename, \"a\") as handle:\n",
    "        handle.write(data)\n",
    "\n",
    "\n",
    "def make_tarfile(output_filename, source_dir, archive_name, custom_filter=None):\n",
    "    # Helper for filtering out modification timestamps\n",
    "    def _filter_timestamps(tar_info):\n",
    "        tar_info.mtime = 0\n",
    "        return tar_info if custom_filter is None else custom_filter(tar_info)\n",
    "\n",
    "    unzipped_filename = tempfile.mktemp()\n",
    "    try:\n",
    "        with tarfile.open(unzipped_filename, \"w\") as tar:\n",
    "            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)\n",
    "        # When gzipping the tar, don't include the tar's filename or modification time in the\n",
    "        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n",
    "        with gzip.GzipFile(filename=\"\", fileobj=open(output_filename, 'wb'), mode='wb', mtime=0)\\\n",
    "                as gzipped_tar, open(unzipped_filename, 'rb') as tar:\n",
    "            gzipped_tar.write(tar.read())\n",
    "    finally:\n",
    "        os.remove(unzipped_filename)\n",
    "\n",
    "\n",
    "def _copy_project(src_path, dst_path=\"\"):\n",
    "    \"\"\"\n",
    "    Internal function used to copy MLflow project during development.\n",
    "    Copies the content of the whole directory tree except patterns defined in .dockerignore.\n",
    "    The MLflow is assumed to be accessible as a local directory in this case.\n",
    "    :param dst_path: MLflow will be copied here\n",
    "    :return: name of the MLflow project directory\n",
    "    \"\"\"\n",
    "\n",
    "    def _docker_ignore(mlflow_root):\n",
    "        docker_ignore = os.path.join(mlflow_root, '.dockerignore')\n",
    "        patterns = []\n",
    "        if os.path.exists(docker_ignore):\n",
    "            with open(docker_ignore, \"r\") as f:\n",
    "                patterns = [x.strip() for x in f.readlines()]\n",
    "\n",
    "        def ignore(_, names):\n",
    "            import fnmatch\n",
    "            res = set()\n",
    "            for p in patterns:\n",
    "                res.update(set(fnmatch.filter(names, p)))\n",
    "            return list(res)\n",
    "\n",
    "        return ignore if patterns else None\n",
    "\n",
    "    mlflow_dir = \"arthur-project\"\n",
    "    # check if we have project root\n",
    "    assert os.path.isfile(os.path.join(src_path, \"setup.py\")), \"file not found \" + str(\n",
    "        os.path.abspath(os.path.join(src_path, \"setup.py\")))\n",
    "    shutil.copytree(src_path, os.path.join(dst_path, mlflow_dir),\n",
    "                    ignore=_docker_ignore(src_path))\n",
    "    return mlflow_dir\n",
    "\n",
    "\n",
    "def _copy_file_or_tree(src, dst, dst_dir=None):\n",
    "    \"\"\"\n",
    "    :return: The path to the copied artifacts, relative to `dst`\n",
    "    \"\"\"\n",
    "    dst_subpath = os.path.basename(os.path.abspath(src))\n",
    "    if dst_dir is not None:\n",
    "        dst_subpath = os.path.join(dst_dir, dst_subpath)\n",
    "    dst_path = os.path.join(dst, dst_subpath)\n",
    "\n",
    "    dst_dirpath = os.path.dirname(dst_path)\n",
    "    if not os.path.exists(dst_dirpath):\n",
    "        os.makedirs(dst_dirpath)\n",
    "\n",
    "    if os.path.isfile(src):\n",
    "        shutil.copy(src=src, dst=dst_path)\n",
    "    else:\n",
    "        shutil.copytree(src=src, dst=dst_path)\n",
    "    return dst_subpath\n",
    "\n",
    "\n",
    "def get_parent_dir(path):\n",
    "    return os.path.abspath(os.path.join(path, os.pardir))\n",
    "\n",
    "def list_all_filepaths(absolute_dirpath):\n",
    "    \"\"\"Returns all filepaths within dir relative to dir root\"\"\"\n",
    "    return [\n",
    "        os.path.relpath(os.path.join(dirpath, file), absolute_dirpath)\n",
    "        for (dirpath, dirnames, filenames) in os.walk(absolute_dirpath)\n",
    "        for file in filenames\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing store/abstract_store.py\n"
     ]
    }
   ],
   "source": [
    "%%file store/abstract_store.py\n",
    "from abc import abstractmethod, ABCMeta\n",
    "from Arthur.core.utils.entities.ViewType import ViewType\n",
    "\n",
    "\n",
    "class AbstractStore:\n",
    "    \"\"\"\n",
    "    Abstract class for Backend Storage\n",
    "    This class will define API interface for front ends to connect with various types of backends\n",
    "    \"\"\"\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Empty constructor for now. This is deliberately not marked as abstract, else every\n",
    "        derived class would be forced to create one.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing entities/ViewType.py\n"
     ]
    }
   ],
   "source": [
    "%%file entities/ViewType.py\n",
    "class ViewType(object):\n",
    "    \"\"\"Enum to filter requested experiment types.\"\"\"\n",
    "    ACTIVE_ONLY, DELETED_ONLY, ALL = range(1, 4)\n",
    "    _VIEW_TO_STRING = {\n",
    "        ACTIVE_ONLY: \"active_only\",\n",
    "        DELETED_ONLY: \"deleted_only\",\n",
    "        ALL: \"all\",\n",
    "    }\n",
    "    _STRING_TO_VIEW = {value: key for key, value in _VIEW_TO_STRING.items()}\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, view_str):\n",
    "        if view_str not in cls._STRING_TO_VIEW:\n",
    "            raise Exception(\n",
    "                \"Could not get valid view type corresponding to string %s. \"\n",
    "                \"Valid view types are %s\" % (view_str, list(cls._STRING_TO_VIEW.keys())))\n",
    "        return cls._STRING_TO_VIEW[view_str]\n",
    "\n",
    "    @classmethod\n",
    "    def to_string(cls, view_type):\n",
    "        if view_type not in cls._VIEW_TO_STRING:\n",
    "            raise Exception(\n",
    "                \"Could not get valid view type corresponding to string %s. \"\n",
    "                \"Valid view types are %s\" % (view_type, list(cls._VIEW_TO_STRING.keys())))\n",
    "        return cls._VIEW_TO_STRING[view_type]\n",
    "#ViewType.ALL\n",
    "#ViewType._STRING_TO_VIEW\n",
    "#ViewType.from_string('active_only')\n",
    "#ViewType.to_string(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting algo_publish.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%file algo_publish.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "from submitted_run import LocalSubmittedRun\n",
    "import shlex\n",
    "\n",
    "__version__ = '0.0.8'\n",
    "APIFLY_FUNCTIONS=\"APIFLY_FUNCTIONS\"\n",
    "APIFLY_TOKEN=\"APIFLY_TOKEN\"\n",
    "STATIC_PREFIX_ENV_VAR=\"STATIC_PREFIX_ENV_VAR\"\n",
    "\n",
    "_logger = logging.getLogger(__name__)\n",
    "def _runServerCmdbase(apifly_function, apifly_token, host, port, workers, static_prefix,gunicorn_opts):\n",
    "    \"\"\"\n",
    "    Run the Arthur api server, wrapping it in gunicorn\n",
    "    :param static_prefix: If set, the index.html asset will be served from the path static_prefix.\n",
    "                          If left None, the index.html asset will be served from the root path.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    env_map = {}\n",
    "    if apifly_function:\n",
    "        env_map[APIFLY_FUNCTIONS] = apifly_function\n",
    "    if apifly_token:\n",
    "        env_map[APIFLY_TOKEN] = apifly_token\n",
    "    if static_prefix:\n",
    "        env_map[STATIC_PREFIX_ENV_VAR] = static_prefix\n",
    "    \n",
    "    bind_address = \"%s:%s\" % (host, port)\n",
    "    \n",
    "    opts = shlex.split(gunicorn_opts) if gunicorn_opts else []\n",
    "    exec_cmd([\"gunicorn\"] + opts + [\"-b\", bind_address, \"-w\", \"%s\" % workers,\n",
    "                                    \"--worker-class\",\"gevent\",\n",
    "                                    \"Arthur.core.apiserver.main:app\"],\n",
    "             env=env_map, stream_output=True)\n",
    "    \n",
    "class model_publish(object):\n",
    "    def _run_arthur_run_cmd(self,arthur_run_arr,apifly_function, apifly_token='',static_prefix='',env_map={}):\n",
    "        \"\"\"\n",
    "        Invoke ``arthur run`` in a subprocess, which in turn runs the entry point in a child process.\n",
    "        Returns a handle to the subprocess. Popen launched to invoke ``arthur run``.\n",
    "        \"\"\"\n",
    "        #final_env = os.environ.copy()\n",
    "        #env_map = {}\n",
    "        if apifly_function:\n",
    "            env_map[APIFLY_FUNCTIONS] = apifly_function\n",
    "        if apifly_token:\n",
    "            env_map[APIFLY_TOKEN] = apifly_token\n",
    "        if static_prefix:\n",
    "            env_map[STATIC_PREFIX_ENV_VAR] = static_prefix\n",
    "        cmd_env = os.environ.copy()\n",
    "        if env_map:\n",
    "            cmd_env.update(env_map)\n",
    "        #final_env.update(env_map)\n",
    "        # Launch `mlflow run` command as the leader of its own process group so that we can do a\n",
    "        # best-effort cleanup of all its descendant processes if needed\n",
    "        return subprocess.Popen(\n",
    "            arthur_run_arr, env=cmd_env, universal_newlines=True, preexec_fn=os.setsid)\n",
    "\n",
    "    def _build_arthur_run_cmd(self,runpath='', port=None, workers=None, parameters=None,gunicorn_opts=''):\n",
    "        \"\"\"\n",
    "        Build and return an array containing an ``Arthur run`` command that can be invoked to locally\n",
    "        run the project at the specified URI.\n",
    "        Run the Arthur api server, wrapping it in gunicorn\n",
    "    :param static_prefix: If set, the index.html asset will be served from the path static_prefix.\n",
    "        If left None, the index.html asset will be served from the root path.\n",
    "    :return: None\n",
    "    \n",
    "        \"\"\"\n",
    "        if workers is not None:\n",
    "            #arthur_run_arr.extend([\"-w\", str(workers)])\n",
    "            workers=str(workers)\n",
    "        else:\n",
    "            #arthur_run_arr.extend([\"-w\", '2'])\n",
    "            workers=str(2)\n",
    "        if port is not None:\n",
    "            #arthur_run_arr.extend([\"-p\", str(port)])\n",
    "            port=port\n",
    "        else:\n",
    "            #arthur_run_arr.extend([\"-p\", '5002']) \n",
    "            port ='5002'\n",
    "\n",
    "        host =\"0.0.0.0\"\n",
    "        bind_address = \"%s:%s\" % (host, port)\n",
    "        gunicorn_opts+=\"--chdir %s\"%runpath  #\"--chdir ../dep_test/\"\n",
    "        opts = shlex.split(gunicorn_opts) if gunicorn_opts else []\n",
    "        base_arr=[\"gunicorn\"] + opts + [\"-b\", bind_address, \"-w\", \"%s\" % workers,\n",
    "                                    \"--worker-class\",\"gevent\",\n",
    "                                    \"Arthur.core.apiserver.main:app\"]\n",
    "        \n",
    "        #arthur_run_arr = [\"Arthur\", \"apiserver\", \"-f\", apifuncs,\"-h\",\"0.0.0.0\"]\n",
    "\n",
    "        #if not use_conda:\n",
    "        #    pass\n",
    "            #mlflow_run_arr.append(\"--no-conda\")\n",
    "        if parameters is not None:\n",
    "            for key, value in parameters.items():\n",
    "                base_arr.extend([\"-P\", \"%s=%s\" % (key, value)])\n",
    "        return base_arr#arthur_run_arr\n",
    "    def _invoke_arthur_run_subprocess(self,apifuncs,experiment_id, run_id,token='',runpath='',port=None, workers=None, parameters=None,\\\n",
    "                                      gunicorn_opts='',static_prefix=''):\n",
    "        \"\"\"\n",
    "        Run an Arthur project asynchronously by invoking ``Arthur run`` in a subprocess, returning\n",
    "        a SubmittedRun that can be used to query run status.\n",
    "        \"\"\"\n",
    "        _logger.info(\"=== Asynchronously launching Arthur run with ID %s ===\", run_id)\n",
    "        arthur_run_arr = self._build_arthur_run_cmd(runpath=runpath,port=port, workers=workers,parameters=parameters,\\\n",
    "                                                   gunicorn_opts=gunicorn_opts)\n",
    "        #print 'arthur_run_arr',arthur_run_arr\n",
    "        arthur_run_subprocess = self._run_arthur_run_cmd(arthur_run_arr,apifuncs,token,static_prefix=static_prefix)\n",
    "        #print 'arthur_run_subprocess',arthur_run_subprocess.stdout.read()#打印结果\n",
    "        return LocalSubmittedRun(run_id, arthur_run_subprocess)\n",
    "    def run_nohup(self,arthur_run_arr,run_id):\n",
    "        \"\"\"\n",
    "        Run an Arthur project asynchronously by invoking ``Arthur run`` in a subprocess, returning\n",
    "        a SubmittedRun that can be used to query run status.\n",
    "        \"\"\"\n",
    "        _logger.info(\"=== Asynchronously launching Arthur run with ID %s ===\", run_id)\n",
    "        arthur_run_subprocess = self._run_arthur_run_cmd(\n",
    "            [arthur_run_arr])\n",
    "        return LocalSubmittedRun(run_id, arthur_run_subprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Arthur.core.utils.algo_publish import model_publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arthur_run_arr ['gunicorn', '--chdir', '/Users/leepand/Downloads/recom/python_web/Arthur.io/Arthur/core/entities/base/tests', '-b', '0.0.0.0:5002', '-w', '2', '--worker-class', 'gevent', 'Arthur.core.apiserver.main:app']\n"
     ]
    }
   ],
   "source": [
    "publish_class=model_publish()\n",
    "#x=Spinner()\n",
    "#x.start()\n",
    "publish_status = publish_class._invoke_arthur_run_subprocess('fib.fib',1,2,runpath='/Users/leepand/Downloads/recom/python_web/Arthur.io/Arthur/core/entities/base/tests')\n",
    "#_wait_for(publish_status)\n",
    "#x.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'publish_status' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8587bc2f1228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpublish_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'publish_status' is not defined"
     ]
    }
   ],
   "source": [
    "publish_status.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "publish_class=model_publish()\n",
    "\n",
    "publish_status2 = publish_class._invoke_arthur_run_subprocess('fib.fib',1,2,token='test',port=5005,runpath='/Users/leepand/Downloads/recom/python_web/Arthur.io/Arthur/core/entities/base/tests')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RUNNING', 30617)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_status2.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ad6c0c508c84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "pp = subprocess.Popen(['ls','./'], stdout=subprocess.PIPE)\n",
    "stdout, stderr = pp.communicate()\n",
    "lines = stdout.decode('ascii').split('\\n')\n",
    "out = dict([[x.strip().rsplit('.')[-1] for x in l.split(':')] for l in lines if l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'__init__.py',\n",
       " u'algo_publish.py',\n",
       " u'entities',\n",
       " u'env.py',\n",
       " u'experiment',\n",
       " u'port_for',\n",
       " u'spinner.py',\n",
       " u'store',\n",
       " u'submitted_run.py',\n",
       " u'test.ipynb',\n",
       " u'token_util.py',\n",
       " u'']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Arthur.core.utils.store.exp_file_process import FileStore\n",
    "project_path=os.path.abspath('arthur_runs/'+'leepand')\n",
    "rel_path='arthur_runs/'+'leepand'\n",
    "#project_path='./'\n",
    "create_exp=FileStore(root_directory=project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Arthur.core.utils.store.exp_file_process.FileStore at 0x10dcf0750>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "projectname='new_leepand'\n",
    "funcspath='/Users/leepand/Downloads/recom/python_web/Arthur.io/Arthur/core/entities/base/tests'\n",
    "create_exp.create_experiment(funcspath,projectname)\n",
    "funcspath_bath = os.path.join(create_exp.get_experiment_by_name(projectname).artifact_location,projectname)\n",
    "\n",
    "    \n",
    "        \n",
    "        #shell_cmd=nohup command > logfile.txt & echo $! > pidfile.txt\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        build_shell_cmd=publish_class._build_arthur_run_cmd(apifuncs=self.funclist,token=Token_info,runpath=run_path, port=self.port, workers=None, parameters=None)\n",
    "        #将执行命令写入项目目录\n",
    "        codepath=create_exp.get_experiment_by_name(self.projectname).artifact_location\n",
    "        generated_code_filename = os.path.join(codepath,\"run.sh\")\n",
    "        with open(generated_code_filename, \"w\") as f:\n",
    "            f.write(' '.join(build_shell_cmd))\n",
    "        #remarks=self.remark\n",
    "        #remarks.replaceAll(\"[^0-9a-zA-Z\\u4e00-\\u9fa5.，,。？“”]\", \"\");\n",
    "        #return HjsOrder.order_add(self.cId, self.otype, self.order_tm, self.start_tm, self.end_tm, self.amount, self.cash, self.remark)\n",
    "        return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cmdDeploy(projectName,funcsPath,userName,):\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Arthur.core.utils.store.exp_file_process import FileStore\n",
    "from Arthur.core.utils.store.file_utils import list_subdirs\n",
    "from Arthur.core.utils import  port_for\n",
    "from Arthur.core.utils.token_util import Connector\n",
    "from Arthur.core.entities.bean.Arthur_service import ArthurService\n",
    "from Arthur.core.entities.base.bs_time import get_cur_day\n",
    "from Arthur.core.entities.bean.hjs_user import HjsUser\n",
    "\n",
    "\n",
    "def algoInfoAdd(userName,projectName,funcsPath,funcList,algoField=1,port=None):\n",
    "    _bRet,uId=HjsUser.get_user_uid(userName)\n",
    "    if not _bRet:\n",
    "        return False, uId  \n",
    "    project_path=os.path.abspath('arthur_runs/'+userName)\n",
    "    rel_path='arthur_runs/'+userName\n",
    "    create_exp=FileStore(root_directory=project_path)\n",
    "    #迁移源项目路径至新建路径\n",
    "    create_exp.create_experiment(funcsPath,projectName)\n",
    "    Token_gen=Connector.encrypt_token( 1, str(uId), 'session_token')\n",
    "    Token_info=Token_gen['token']\n",
    "    funcspath_bath = os.path.join(create_exp.get_experiment_by_name(projectName).artifact_location,projectName)\n",
    "    funcs_sub=list_subdirs(funcspath_bath)\n",
    "    run_path=os.path.join(funcspath_bath,funcs_sub[0])#一个项目只有一个主目录-default\n",
    "    if port is None:\n",
    "        port=port_for.select_random()\n",
    "    projecttm = get_cur_day(0, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    remark=\"请到主页编辑添加\"\n",
    "    emailmsg=\"是\"\n",
    "    opertype=\"publish\"\n",
    "    projectdesc=\"暂无描述，请到主页编辑添加\"\n",
    "    tags='Machine Learning'\n",
    "    ArthurService.service_add(uId,projectName, projectdesc,opertype,rel_path,\n",
    "                                     funcList,tags,algoField,'0.0.0.0',port,projecttm,emailmsg,str(remark))\n",
    "    return create_exp,uId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28/01/2019 11:03:12][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): select * from tb_algo where uid = %s and algoname = %s\t[1, 'leepand3']\n",
      "[28/01/2019 11:03:12][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n"
     ]
    }
   ],
   "source": [
    "_bRet,algoInfo = ArthurService.algo_proj_info(1,'leepand3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoInfo['aid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Arthur.core.utils.algo_publish import model_publish\n",
    "\n",
    "def algoDeploy(userName,projectName,funcsPath,funcList):\n",
    "    create_exp_info,uId = algoInfoAdd(userName,projectName,funcsPath,funcList)\n",
    "    _bRet,algoInfo = ArthurService.algo_proj_info(uId,projectName)#AlgoName=projectName\n",
    "    #funcslist=algoInfo['funcslist']\n",
    "    port=algoInfo['port']\n",
    "    token=algoInfo['token']\n",
    "    aId = algoInfo['aid']\n",
    "    experiment_id=create_exp_info.get_experiment_by_name(projectName).experiment_id\n",
    "    runId= aId\n",
    "    funcspath_bath = os.path.join(create_exp_info.get_experiment_by_name(projectName).artifact_location,projectName)        \n",
    "    funcs_sub=list_subdirs(funcspath_bath)\n",
    "    run_path=os.path.join(funcspath_bath,funcs_sub[0])\n",
    "    publish_class=model_publish()\n",
    "    publish_status = publish_class._invoke_arthur_run_subprocess(funcList,experiment_id,runId,token=token,port=port,runpath=run_path)\n",
    "    #将pid写入项目目录\n",
    "    pidPath=create_exp_info.get_experiment_by_name(projectName).artifact_location\n",
    "    publish_status,pid_info = publish_status.get_status()\n",
    "    generated_pid_filename = os.path.join(pidPath,\"pid.pid\")\n",
    "    with open(generated_pid_filename, \"w\") as f:\n",
    "        f.write(str(pid_info))\n",
    "    wait_result = wait_until_algo_published(publish_status,aId)\n",
    "    if wait_result:\n",
    "        return True,'algo deploy success'\n",
    "    else:\n",
    "        return False,'algo deploy failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28/01/2019 12:24:18][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): select * from tb_user where username = %s\t['leepand6']\n",
      "[28/01/2019 12:24:18][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n",
      "[28/01/2019 12:24:18][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): insert into tb_algo(uid, algoname, algodesc,opertype,token,pyfile,funcslist,tags,field,host,port,atype, algo_tm, is_email,remark, insert_tm) values(%s, %s, %s, %s, %s, %s,%s, %s, %s, %s, %s, %s,%s, %s,%s,%s)\t[1, 'leepand10', '\\xe6\\x9a\\x82\\xe6\\x97\\xa0\\xe6\\x8f\\x8f\\xe8\\xbf\\xb0\\xef\\xbc\\x8c\\xe8\\xaf\\xb7\\xe5\\x88\\xb0\\xe4\\xb8\\xbb\\xe9\\xa1\\xb5\\xe7\\xbc\\x96\\xe8\\xbe\\x91\\xe6\\xb7\\xbb\\xe5\\x8a\\xa0', 'publish', '20bf7679146eaef99136cde84ccc1eba', 'arthur_runs/leepand6', 'fib.fib', 'Machine Learning', 1, '0.0.0.0', 22169, 'REST', '2019-01-28 12:24:18', '\\xe6\\x98\\xaf', '\\xe8\\xaf\\xb7\\xe5\\x88\\xb0\\xe4\\xb8\\xbb\\xe9\\xa1\\xb5\\xe7\\xbc\\x96\\xe8\\xbe\\x91\\xe6\\xb7\\xbb\\xe5\\x8a\\xa0', '2019-01-28 12:24:18']\n",
      "[28/01/2019 12:24:18][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n",
      "[28/01/2019 12:24:18][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): select * from tb_algo where uid = %s and algoname = %s\t[1, 'leepand10']\n",
      "[28/01/2019 12:24:19][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28/01/2019 12:24:40][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): update tb_algo set status = %s,insert_tm = %s where aid = %s\t['normal', '2019-01-28 12:24:40', 31]\n",
      "[28/01/2019 12:24:40][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b"
     ]
    }
   ],
   "source": [
    "projectName='leepand10'\n",
    "userName=\"leepand6\"\n",
    "funcsPath='/Users/leepand/Downloads/recom/python_web/Arthur.io/Arthur/core/entities/base/tests'\n",
    "funcList='fib.fib'\n",
    "#c = algoInfoAdd(userName,projectName,funcsPath,funcList)\n",
    "publish,_ = algoDeploy(userName,projectName,funcsPath,funcList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _wait_for(submitted_run_obj):\n",
    "    \"\"\"Wait on the passed-in submitted run, reporting its status to the tracking server.\"\"\"\n",
    "    run_id = submitted_run_obj.run_id\n",
    "    active_run = None\n",
    "    # Note: there's a small chance we fail to report the run's status to the tracking server if\n",
    "    # we're interrupted before we reach the try block below\n",
    "    try:\n",
    "        active_run = tracking.MlflowClient().get_run(run_id) if run_id is not None else None\n",
    "        if submitted_run_obj.wait():\n",
    "            _logger.info(\"=== Run (ID '%s') succeeded ===\", run_id)\n",
    "            _maybe_set_run_terminated(active_run, \"FINISHED\")\n",
    "        else:\n",
    "            _maybe_set_run_terminated(active_run, \"FAILED\")\n",
    "            raise ExecutionException(\"Run (ID '%s') failed\" % run_id)\n",
    "    except KeyboardInterrupt:\n",
    "        _logger.error(\"=== Run (ID '%s') interrupted, cancelling run ===\", run_id)\n",
    "        submitted_run_obj.cancel()\n",
    "        _maybe_set_run_terminated(active_run, \"FAILED\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "def wait_until_algo_published(\n",
    "    publish_status,aId, max_wait_sec=20, interval_sec=0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    wait util the algo published or timeout\n",
    "    :param publish_status:\n",
    "        publish status for wait :RUNNING,FAILED,FINISHED\n",
    "    :param max_wait_sec:\n",
    "        max wating time until timeout\n",
    "    :param interval_sec:\n",
    "        check interval\n",
    "    :param recursive:\n",
    "        recursively search or not\n",
    "    :return:\n",
    "        True if found.\n",
    "    \"\"\"\n",
    "    curr_wait_sec = 0\n",
    "    spinner_generator = itertools.cycle(['-', '/', '|', '\\\\'])\n",
    "    while curr_wait_sec < max_wait_sec:\n",
    "        \n",
    "        if publish_status==\"FAILED\" or publish_status==\"FINISHED\" :\n",
    "            ArthurService.algo_publish_status_update(aId,'stop')\n",
    "            return False\n",
    "        curr_wait_sec += interval_sec\n",
    "        sys.stdout.write(next(spinner_generator))\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(interval_sec)\n",
    "        sys.stdout.write('\\b')  \n",
    "    ArthurService.algo_publish_status_update(aId,'normal')\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RUNNING'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "import threading\n",
    "\n",
    "\n",
    "class wait_for_algodeploy:\n",
    "    def __init__(self, delay=0.1):\n",
    "        self.spinner_generator = itertools.cycle(['-', '/', '|', '\\\\'])\n",
    "        if delay and float(delay): self.delay = delay\n",
    "\n",
    "    def spinner_task(self):\n",
    "        while self.busy:\n",
    "            sys.stdout.write(next(self.spinner_generator))\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(self.delay)\n",
    "            sys.stdout.write('\\b')\n",
    "\n",
    "    def start(self):\n",
    "        self.busy = True\n",
    "        threading.Thread(target=self.spinner_task).start()\n",
    "        return True\n",
    "\n",
    "    def stop(self):\n",
    "        self.busy = False\n",
    "        time.sleep(self.delay)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<ipython-input-30-db63534e46cb>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "def get_filename(backstep=0):\n",
    "    \"\"\"\n",
    "    Get the file name of the current code line.\n",
    "    :param backstep:\n",
    "        will go backward (one layer) from the current function call stack\n",
    "    \"\"\"\n",
    "    return os.path.basename(\n",
    "        sys._getframe(backstep + 1).f_code.co_filename)  # pylint:disable=W0212\n",
    "get_filename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.get_experiment_by_name(projectName).experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/leepand/Downloads/recom/python_web/Arthur.io/Arthur/core/utils/arthur_runs/leepand/0/new_leepand'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcspath_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_exp.get_experiment_by_name(projectname).experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28/01/2019 08:46:39][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): select * from tb_user where username = %s\t['leepand6']\n",
      "[28/01/2019 08:46:39][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n"
     ]
    }
   ],
   "source": [
    "from Arthur.core.entities.bean.hjs_user import HjsUser\n",
    "\n",
    "_bRet,uId=HjsUser.get_user_uid('leepand6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Arthur.core.controller.deploy.driver.arthur_microservice import ArthurMicroserviceDeployDriver\n",
    "test = ArthurMicroserviceDeployDriver('remore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[29/01/2019 08:26:49][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): select * from tb_user where username = %s\t['leepand6']\n",
      "[29/01/2019 08:26:49][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b/"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[29/01/2019 08:26:50][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): insert into tb_algo(uid, algoname, algodesc,opertype,token,pyfile,funcslist,tags,field,host,port,atype, algo_tm, is_email,remark, insert_tm) values(%s, %s, %s, %s, %s, %s,%s, %s, %s, %s, %s, %s,%s, %s,%s,%s)\t[1, 'None', '\\xe6\\x9a\\x82\\xe6\\x97\\xa0\\xe6\\x8f\\x8f\\xe8\\xbf\\xb0\\xef\\xbc\\x8c\\xe8\\xaf\\xb7\\xe5\\x88\\xb0\\xe4\\xb8\\xbb\\xe9\\xa1\\xb5\\xe7\\xbc\\x96\\xe8\\xbe\\x91\\xe6\\xb7\\xbb\\xe5\\x8a\\xa0', 'publish', '20bf7679146eaef99136cde84ccc1eba', 'arthur_runs/leepand6', 'fib.fib', 'Machine Learning', 1, '0.0.0.0', 48322, 'REST', '2019-01-29 08:26:50', '\\xe6\\x98\\xaf', '\\xe8\\xaf\\xb7\\xe5\\x88\\xb0\\xe4\\xb8\\xbb\\xe9\\xa1\\xb5\\xe7\\xbc\\x96\\xe8\\xbe\\x91\\xe6\\xb7\\xbb\\xe5\\x8a\\xa0', '2019-01-29 08:26:50']\n",
      "[29/01/2019 08:26:50][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[29/01/2019 08:26:50][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): select * from tb_algo where uid = %s and algoname = %s\t[1, 'None']\n",
      "[29/01/2019 08:26:50][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[29/01/2019 08:27:11][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): update tb_algo set status = %s,insert_tm = %s where aid = %s\t['normal', '2019-01-29 08:27:11', 35]\n",
      "[29/01/2019 08:27:11][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n",
      "[29/01/2019 08:27:11][INFO]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/controller/deploy/driver/arthur_microservice.py::wait_until_algo_published(61): ****RESP: algorithm service publish success!\n",
      "[29/01/2019 08:27:11][INFO]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/controller/deploy/driver/arthur_microservice.py::algoDeployCli(156): algo deploy success\n",
      "[29/01/2019 08:27:11][INFO]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/controller/deploy/driver/arthur_microservice.py::algoDeployCli(157): the end point of your algo service fib.fib is 0.0.0.0:48322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 'algo deploy success')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcsPath='/Users/leepand/Downloads/recom/python_web/Arthur.io/Arthur/core/entities/base/tests'\n",
    "funcList='fib.fib'\n",
    "token='haha'\n",
    "test.algoDeployCli(funcsPath,funcList,userName='leepand6',projectName='None',port=None,token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28/01/2019 14:51:36][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): select * from tb_user where username = %s\t['Boris']\n",
      "[28/01/2019 14:51:36][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n",
      "[28/01/2019 14:51:36][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): insert into tb_algo(uid, algoname, algodesc,opertype,token,pyfile,funcslist,tags,field,host,port,atype, algo_tm, is_email,remark, insert_tm) values(%s, %s, %s, %s, %s, %s,%s, %s, %s, %s, %s, %s,%s, %s,%s,%s)\t[2, 'leepand13', '\\xe6\\x9a\\x82\\xe6\\x97\\xa0\\xe6\\x8f\\x8f\\xe8\\xbf\\xb0\\xef\\xbc\\x8c\\xe8\\xaf\\xb7\\xe5\\x88\\xb0\\xe4\\xb8\\xbb\\xe9\\xa1\\xb5\\xe7\\xbc\\x96\\xe8\\xbe\\x91\\xe6\\xb7\\xbb\\xe5\\x8a\\xa0', 'publish', '2a9f9670106e9ef9d456491840cc9eba', 'arthur_runs/Boris', 'fib.fib', 'Machine Learning', 1, '0.0.0.0', 33520, 'REST', '2019-01-28 14:51:36', '\\xe6\\x98\\xaf', '\\xe8\\xaf\\xb7\\xe5\\x88\\xb0\\xe4\\xb8\\xbb\\xe9\\xa1\\xb5\\xe7\\xbc\\x96\\xe8\\xbe\\x91\\xe6\\xb7\\xbb\\xe5\\x8a\\xa0', '2019-01-28 14:51:36']\n",
      "[28/01/2019 14:51:36][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n",
      "[28/01/2019 14:51:36][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): select * from tb_algo where uid = %s and algoname = %s\t[2, 'leepand13']\n",
      "[28/01/2019 14:51:36][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28/01/2019 14:51:57][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_exec_cmdstr(106): update tb_algo set status = %s,insert_tm = %s where aid = %s\t['normal', '2019-01-28 14:51:57', 33]\n",
      "[28/01/2019 14:51:57][DEBUG]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/entities/base/bs_database_pid.py::_new_conn(31): conn(host: 127.0.0.1, port: 3306, user: root, passwd: , db: Arthur_manage)\n",
      "[28/01/2019 14:51:57][INFO]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/controller/deploy/driver/arthur_microservice.py::wait_until_algo_published(60): ****RESP: algorithm service publish success!\n",
      "[28/01/2019 14:51:57][INFO]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/controller/deploy/driver/arthur_microservice.py::algoDeployCli(135): algo deploy success\n",
      "[28/01/2019 14:51:57][INFO]/Users/leepand/anaconda2/lib/python2.7/site-packages/Arthur-2.0.1.dev1-py2.7.egg/Arthur/core/controller/deploy/driver/arthur_microservice.py::algoDeployCli(136): the end point of your algo service fib.fib is 0.0.0.0:33520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 'algo deploy success')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectName='leepand13'\n",
    "userName=\"Boris\"\n",
    "funcsPath='/Users/leepand/Downloads/recom/python_web/Arthur.io/Arthur/core/entities/base/tests'\n",
    "funcList='fib.fib'\n",
    "#c = algoInfoAdd(userName,projectName,funcsPath,funcList)\n",
    "test2 = ArthurMicroserviceDeployDriver('remote')\n",
    "token='aa'\n",
    "test2.algoDeployCli(funcsPath,funcList,userName,projectName,port=None,token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Arthur.core.apiserver.client import Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing misc_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%file misc_functions.py\n",
    "from Arthur.core.entities.base.bs_log import Log\n",
    "import subprocess\n",
    "# class for colors\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "class Commands(object):\n",
    "    def __init__(self):\n",
    "        Log.info(\"handling command cmd script\")\n",
    "\n",
    "    def run_cmd(self, shell_cmd):\n",
    "        try:\n",
    "            if type(shell_cmd) is list:\n",
    "                p = subprocess.Popen(shell_cmd, stdout=subprocess.PIPE)\n",
    "                out, e = p.communicate()\n",
    "                Log.info(\"%s\"%\n",
    "                        (shell_cmd))\n",
    "                if e:\n",
    "                    Log.info(e)\n",
    "                    Log.info(\n",
    "                        bcolors.FAIL + \"error while running the command %s\" %\n",
    "                        (shell_cmd))\n",
    "                else:\n",
    "                    return {'output': out, 'status': True}\n",
    "            else:\n",
    "                process_returncode = subprocess.Popen(\n",
    "                    shell_cmd, shell=True).wait()\n",
    "                Log.info(\"\")\n",
    "                if process_returncode == 0:\n",
    "                    return {'status': True}\n",
    "                else:\n",
    "                    return {'status': False}\n",
    "        except Exception as e:\n",
    "            Log.info(e)\n",
    "            Log.info(bcolors.FAIL + \"error while running the command %s\" %\n",
    "                          (shell_cmd))\n",
    "            return {'status': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Arthur.core.apiserver.client import Client\n",
    "fibclient=Client('http://127.0.0.01:33520',auth_token=\"2a9f9670106e9ef9d456491840cc9eba\")\n",
    "fibclient.fib(n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "func2() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-724d252ad32a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# print(test.func1('hello'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: func2() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "class test:\n",
    "    @staticmethod\n",
    "    def func1():\n",
    "        print('1')\n",
    "    \n",
    "    @staticmethod\n",
    "    def func2(e):\n",
    "        print(e)\n",
    "\n",
    "def other(func):\n",
    "    result = func()\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # print(test.func1('hello'))\n",
    "    other(test.func2('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate 'str' and 'dict' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-765b63363205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'func1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'func2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'world'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-765b63363205>\u001b[0m in \u001b[0;36mother\u001b[0;34m(func, func_param)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mexec_statement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'result=test.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'(\"'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfunc_param\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'\")'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_statement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate 'str' and 'dict' objects"
     ]
    }
   ],
   "source": [
    "class test:\n",
    "    @staticmethod\n",
    "    def func1(p1):\n",
    "        return p1\n",
    "    \n",
    "    @staticmethod\n",
    "    def func2(p2):\n",
    "        return p2\n",
    "\n",
    "def other(func, func_param):\n",
    "    exec_statement = 'result=test.' + func + '(\"' + func_param +'\")'\n",
    "    exec(exec_statement)\n",
    "    loc = locals()\n",
    "    return loc['result']\n",
    "\n",
    "x={'hello':10}\n",
    "if __name__ == '__main__':\n",
    "    print(other('func1', x))\n",
    "    print(other('func2', 'world'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dynamically_load_class.py\n"
     ]
    }
   ],
   "source": [
    "%%file dynamically_load_class.py\n",
    "\"\"\"\n",
    "# https://stackoverflow.com/questions/547829/how-to-dynamically-load-a-python-class\n",
    "\"\"\"\n",
    "import importlib\n",
    "import time\n",
    "#from misc_functions import TraceUsedTime\n",
    "def get_class_contructor(class_location):\n",
    "    mod_path = class_location[:class_location.rfind('.')]\n",
    "    class_name = class_location[class_location.rfind('.') + 1:]\n",
    "    module = importlib.import_module(mod_path)\n",
    "    return getattr(module, class_name)\n",
    "\n",
    "test_de=get_class_contructor(\"misc_functions.TraceUsedTime\")\n",
    "@test_de(True)\n",
    "def test():\n",
    "    time.sleep(3)\n",
    "test()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing json_store.py\n"
     ]
    }
   ],
   "source": [
    "%%file json_store.py\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from io import open\n",
    "try:\n",
    "    to_unicode = unicode\n",
    "except NameError:\n",
    "    to_unicode = str\n",
    "try:\n",
    "\n",
    "    def to_bytes(val):\n",
    "        return bytes(val)\n",
    "\n",
    "    to_bytes(\"test\")\n",
    "except TypeError:\n",
    "\n",
    "    def to_bytes(val):\n",
    "        return bytes(val, \"utf-8\")\n",
    "\n",
    "    to_bytes(\"test\")\n",
    "\n",
    "from Arthur.core.utils.exceptions import (SaveSettingError, FileIOError)\n",
    "\n",
    "\n",
    "class JSONStore():\n",
    "    # TODO:  add file locking\n",
    "    # https://stackoverflow.com/questions/186202/what-is-the-best-way-to-open-a-file-for-exclusive-access-in-python\n",
    "    # Alternatives to JSON??\n",
    "    # https://martin-thoma.com/configuration-files-in-python/\n",
    "    def __init__(self, filepath, initial_dict={}):\n",
    "        self.filepath = filepath\n",
    "        # Ensure filepath directories exist\n",
    "        directory = os.path.dirname(filepath)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        # save initial dictionary\n",
    "        if initial_dict:\n",
    "            self.to_file(initial_dict)\n",
    "        # keep file in memory until a write occurs\n",
    "        self.in_memory_settings = False\n",
    "\n",
    "    def to_file(self, dictionary):\n",
    "        with open(self.filepath, \"wb\") as outfile:\n",
    "            str_ = json.dumps(\n",
    "                dictionary,\n",
    "                indent=4,\n",
    "                sort_keys=True,\n",
    "                separators=(',', ': '),\n",
    "                ensure_ascii=False)\n",
    "            outfile.write(to_bytes(str_))\n",
    "        return\n",
    "\n",
    "    def save(self, key, value):\n",
    "        self.in_memory_settings = False\n",
    "        settings_dict = {}\n",
    "        if not os.path.exists(self.filepath):\n",
    "            open(self.filepath, 'w+').close()\n",
    "        else:\n",
    "            settings_dict = json.load(open(self.filepath, 'r'))\n",
    "        settings_dict[key] = value\n",
    "        with open(self.filepath, \"wb\") as outfile:\n",
    "            str_ = json.dumps(\n",
    "                settings_dict,\n",
    "                indent=4,\n",
    "                sort_keys=True,\n",
    "                separators=(',', ': '),\n",
    "                ensure_ascii=False)\n",
    "            outfile.write(to_bytes(str_))\n",
    "        return\n",
    "\n",
    "    def get(self, name):\n",
    "        if self.in_memory_settings and name in self.in_memory_settings:\n",
    "            return self.in_memory_settings[name]\n",
    "\n",
    "        if not os.path.exists(self.filepath):\n",
    "            return None\n",
    "\n",
    "        with open(self.filepath) as settings_file:\n",
    "            try:\n",
    "                settings = json.load(settings_file)\n",
    "                # save in memory\n",
    "                self.in_memory_settings = settings\n",
    "            except Exception as err:\n",
    "                raise SaveSettingError(err)\n",
    "            if name in settings:\n",
    "                return settings[name]\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    def remove(self, name):\n",
    "        if not os.path.exists(self.filepath):\n",
    "            return None\n",
    "        else:\n",
    "            settings_dict = json.load(open(self.filepath, 'r'))\n",
    "        settings_dict.pop(name, None)\n",
    "        with open(self.filepath, \"wb\") as outfile:\n",
    "            str_ = json.dumps(\n",
    "                settings_dict,\n",
    "                indent=4,\n",
    "                sort_keys=True,\n",
    "                separators=(',', ': '),\n",
    "                ensure_ascii=False)\n",
    "            outfile.write(to_bytes(str_))\n",
    "        return\n",
    "\n",
    "    def to_dict(self):\n",
    "        output_dict = dict()\n",
    "        # reading json file\n",
    "        if os.path.exists(self.filepath):\n",
    "            with open(self.filepath) as data_file:\n",
    "                meta_data_string = data_file.read()\n",
    "            if not meta_data_string:\n",
    "                return {}\n",
    "            try:\n",
    "                output_dict = json.loads(meta_data_string)\n",
    "                output_dict = yaml.safe_load(json.dumps(output_dict))\n",
    "            except Exception as err:\n",
    "                raise FileIOError(err)\n",
    "            return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing exceptions.py\n"
     ]
    }
   ],
   "source": [
    "%%file exceptions.py\n",
    "#!/usr/bin/python\n",
    "#from datmo.core.util.i18n import get as __\n",
    "\n",
    "\n",
    "class ArgumentError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TaskNotComplete(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TaskNoCommandGiven(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TaskInteractiveDetachError(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class SnapshotCreateFromTaskArgs(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class RequiredArgumentMissing(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class GitUrlArgumentError(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TooManyArgumentsFound(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ProjectException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidProjectPath(ProjectException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ProjectNotInitialized(ProjectException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DatmoModelNotInitialized(ProjectException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidOperation(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ClassMethodNotFound(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class CLIArgumentError(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class UnrecognizedCLIArgument(CLIArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidArgumentType(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class MutuallyExclusiveArguments(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ValidationSchemaMissing(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class IncorrectType(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InputError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EntityNotFound(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class MoreThanOneEntityFound(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EntityCollectionNotFound(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class SaveSettingError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class FileExecutionError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class FileAlreadyExistsError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DirAlreadyExistsError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DoesNotExist(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class CodeDoesNotExist(DoesNotExist):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentDoesNotExist(DoesNotExist):\n",
    "    pass\n",
    "\n",
    "\n",
    "class SnapshotDoesNotExist(DoesNotExist):\n",
    "    pass\n",
    "\n",
    "\n",
    "class PathDoesNotExist(FileExecutionError):\n",
    "    def __init__(self, file_path=None):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.file_path:\n",
    "            return \"Path being passed doesn't exist: %s\" % self.file_path\n",
    "        else:\n",
    "            return \"Path being passed doesn't exist\"\n",
    "\n",
    "\n",
    "class LoggingPathDoesNotExist(PathDoesNotExist):\n",
    "    pass\n",
    "\n",
    "\n",
    "class FileIOError(FileExecutionError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class FileStructureError(FileExecutionError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class FileNotInitialized(FileExecutionError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DALException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DALNotInitialized(DALException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentImageNotFound(EnvironmentException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentContainerNotFound(EnvironmentException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentExecutionError(EnvironmentException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentRequirementsCreateError(EnvironmentException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentInitFailed(EnvironmentExecutionError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentConnectFailed(EnvironmentExecutionError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentNotConnected(EnvironmentExecutionError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class EnvironmentNotInitialized(EnvironmentExecutionError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TaskRunError(EnvironmentException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class GPUSupportNotEnabled(EnvironmentExecutionError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class CodeException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class CodeNotInitialized(CodeException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class GitExecutionError(CodeException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class CommitDoesNotExist(CodeException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class CommitFailed(CodeException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidDestinationName(ArgumentError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ValidationFailed(ArgumentError):\n",
    "    def __init__(self, error_obj):\n",
    "        self.errors = error_obj\n",
    "        super(ValidationFailed, self).__init__(\n",
    "            __(\"error\", \"exception.validationfailed\", self.get_error_str()))\n",
    "\n",
    "    def get_error_str(self):\n",
    "        err_str = ''\n",
    "        for name in self.errors:\n",
    "            err_str += \"'%s': %s\\n\" % (name, self.errors[name])\n",
    "        return err_str\n",
    "\n",
    "\n",
    "class DatmoFolderInWorkTree(CodeException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class UnstagedChanges(Exception):\n",
    "    def __str__(self):\n",
    "        return \"Unstaged changes exists. Create a snapshot to remove any unstaged changes\"\n",
    "\n",
    "\n",
    "class NothingToStage(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
